# OctoLLM Development Environment Configuration
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control

# ============================================================================
# Database Configuration
# ============================================================================

# PostgreSQL Database
POSTGRES_DB=octollm
POSTGRES_USER=octollm
POSTGRES_PASSWORD=octollm_dev_password_CHANGE_ME

# Redis Cache
# Leave empty for no password in dev (not recommended for production)
REDIS_PASSWORD=

# ============================================================================
# LLM API Keys (REQUIRED)
# ============================================================================

# OpenAI API Key (required for Orchestrator, Planner, Retriever, Coder, Judge)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (optional, for Claude models)
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# ============================================================================
# Service Configuration
# ============================================================================

# Environment: development, staging, production
ENVIRONMENT=development

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Rust logging level for reflex-layer and executor-arm
# Options: trace, debug, info, warn, error
RUST_LOG=info

# ============================================================================
# Orchestrator Configuration
# ============================================================================

# Maximum number of arms to execute in parallel
MAX_PARALLEL_ARMS=5

# Task execution timeout (seconds)
TASK_TIMEOUT=300

# Cache time-to-live (seconds)
CACHE_TTL=3600

# ============================================================================
# Reflex Layer Configuration
# ============================================================================

# Reflex cache TTL (seconds)
REFLEX_CACHE_TTL=3600

# Rate limiting (requests per minute)
REFLEX_RATE_LIMIT_PER_MINUTE=100

# PII Detection settings
PII_DETECTION_ENABLED=true
PII_AUTO_REDACT=true

# ============================================================================
# Monitoring Configuration (Optional)
# ============================================================================

# Prometheus metrics enabled
PROMETHEUS_ENABLED=false

# Grafana admin password
GRAFANA_ADMIN_PASSWORD=admin_CHANGE_ME

# ============================================================================
# Development Options
# ============================================================================

# Enable hot reload for Python services
HOT_RELOAD=true

# Debug mode (verbose logging)
DEBUG_MODE=false

# ============================================================================
# Advanced Configuration (Optional)
# ============================================================================

# Database connection pool size
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# Redis connection pool size
REDIS_POOL_SIZE=10

# LLM request timeout (seconds)
LLM_TIMEOUT=30

# Maximum request size (MB)
MAX_REQUEST_SIZE=10

# JWT secret for capability tokens
# Generate with: openssl rand -hex 32
JWT_SECRET=your-jwt-secret-here-CHANGE-IN-PRODUCTION

# Allowed origins for CORS (comma-separated)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# ============================================================================
# Cloud Configuration (Production Only - NOT USED IN DEV)
# ============================================================================

# AWS Configuration
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_REGION=us-east-1

# GCP Configuration
# GCP_PROJECT_ID=
# GCP_SERVICE_ACCOUNT_KEY=

# Azure Configuration
# AZURE_SUBSCRIPTION_ID=
# AZURE_CLIENT_ID=
# AZURE_CLIENT_SECRET=
# AZURE_TENANT_ID=

# ============================================================================
# Security Notes
# ============================================================================

# 1. NEVER commit the .env file to version control
# 2. Use strong, unique passwords for production
# 3. Rotate API keys regularly
# 4. Enable 2FA on your LLM provider accounts
# 5. Review security documentation: docs/security/overview.md

# ============================================================================
# Quick Start
# ============================================================================

# 1. Copy this file: cp .env.example .env
# 2. Edit .env with your OpenAI API key
# 3. Start services: docker-compose -f docker-compose.dev.yml up -d
# 4. Check health: curl http://localhost:8000/health
# 5. View logs: docker-compose -f docker-compose.dev.yml logs -f

# ============================================================================
# Support
# ============================================================================

# Documentation: docs/implementation/dev-environment.md
# Troubleshooting: docs/operations/troubleshooting.md
# Issues: https://github.com/doublegate/OctoLLM/issues
