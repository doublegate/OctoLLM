<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>PII Protection - OctoLLM Documentation</title>


        <!-- Custom HTML head -->

        <meta name="description" content="Distributed AI Architecture for Offensive Security and Developer Tooling - Comprehensive technical documentation covering architecture, API, development, operations, and security.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">OctoLLM Documentation</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/doublegate/OctoLLM" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/doublegate/OctoLLM/edit/main/docs/src/security/pii-protection.md" title="Suggest an edit" aria-label="Suggest an edit" rel="edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="pii-protection-and-privacy-implementation-guide"><a class="header" href="#pii-protection-and-privacy-implementation-guide">PII Protection and Privacy Implementation Guide</a></h1>
<p><strong>Security</strong> &gt; PII Protection</p>
<p><strong>Version</strong>: 1.0
<strong>Last Updated</strong>: 2025-11-10
<strong>Status</strong>: Production Ready
<strong>Compliance</strong>: GDPR, CCPA, HIPAA-aware</p>
<p><a href="./README.html">← Back to Security</a> | <a href="../README.html">Documentation Home</a> | <a href="../components/arms/guardian-arm.html">Guardian Arm</a></p>
<hr />
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ol>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#importance-of-pii-protection">Importance of PII Protection</a></li>
<li><a href="#regulatory-landscape">Regulatory Landscape</a></li>
<li><a href="#octollm-pii-strategy">OctoLLM PII Strategy</a></li>
<li><a href="#defense-in-depth-approach">Defense-in-Depth Approach</a></li>
</ul>
</li>
<li><a href="#pii-detection">PII Detection</a>
<ul>
<li><a href="#regex-based-detection">Regex-Based Detection</a></li>
<li><a href="#ner-based-detection">NER-Based Detection</a></li>
<li><a href="#combined-detection-strategy">Combined Detection Strategy</a></li>
<li><a href="#custom-pii-types">Custom PII Types</a></li>
<li><a href="#detection-accuracy">Detection Accuracy</a></li>
</ul>
</li>
<li><a href="#automatic-redaction">Automatic Redaction</a>
<ul>
<li><a href="#redaction-strategies">Redaction Strategies</a></li>
<li><a href="#structure-preserving-redaction">Structure-Preserving Redaction</a></li>
<li><a href="#reversible-redaction">Reversible Redaction</a></li>
<li><a href="#performance-optimization">Performance Optimization</a></li>
</ul>
</li>
<li><a href="#data-sanitization">Data Sanitization</a>
<ul>
<li><a href="#sanitization-for-logging">Sanitization for Logging</a></li>
<li><a href="#sanitization-for-storage">Sanitization for Storage</a></li>
<li><a href="#sanitization-for-external-apis">Sanitization for External APIs</a></li>
<li><a href="#sanitization-testing">Sanitization Testing</a></li>
</ul>
</li>
<li><a href="#gdpr-compliance">GDPR Compliance</a>
<ul>
<li><a href="#right-to-be-forgotten">Right to be Forgotten</a></li>
<li><a href="#data-portability">Data Portability</a></li>
<li><a href="#consent-management">Consent Management</a></li>
<li><a href="#privacy-impact-assessments">Privacy Impact Assessments</a></li>
<li><a href="#data-minimization">Data Minimization</a></li>
</ul>
</li>
<li><a href="#ccpa-compliance">CCPA Compliance</a>
<ul>
<li><a href="#consumer-rights">Consumer Rights</a></li>
<li><a href="#opt-out-mechanisms">Opt-Out Mechanisms</a></li>
<li><a href="#privacy-notices">Privacy Notices</a></li>
<li><a href="#data-sale-disclosure">Data Sale Disclosure</a></li>
</ul>
</li>
<li><a href="#differential-privacy">Differential Privacy</a>
<ul>
<li><a href="#noise-addition">Noise Addition</a></li>
<li><a href="#k-anonymity">K-Anonymity</a></li>
<li><a href="#l-diversity">L-Diversity</a></li>
<li><a href="#privacy-budgets">Privacy Budgets</a></li>
</ul>
</li>
<li><a href="#implementation-integration">Implementation Integration</a>
<ul>
<li><a href="#guardian-arm-integration">Guardian Arm Integration</a></li>
<li><a href="#orchestrator-integration">Orchestrator Integration</a></li>
<li><a href="#logging-system-integration">Logging System Integration</a></li>
<li><a href="#database-layer-integration">Database Layer Integration</a></li>
</ul>
</li>
<li><a href="#testing-and-validation">Testing and Validation</a>
<ul>
<li><a href="#unit-tests">Unit Tests</a></li>
<li><a href="#integration-tests">Integration Tests</a></li>
<li><a href="#compliance-testing">Compliance Testing</a></li>
<li><a href="#penetration-testing">Penetration Testing</a></li>
</ul>
</li>
<li><a href="#operational-procedures">Operational Procedures</a>
<ul>
<li><a href="#incident-response">Incident Response</a></li>
<li><a href="#data-breach-notification">Data Breach Notification</a></li>
<li><a href="#audit-procedures">Audit Procedures</a></li>
<li><a href="#training-and-awareness">Training and Awareness</a></li>
</ul>
</li>
</ol>
<hr />
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<h3 id="importance-of-pii-protection"><a class="header" href="#importance-of-pii-protection">Importance of PII Protection</a></h3>
<p>Personally Identifiable Information (PII) protection is critical for OctoLLM as it operates in security-sensitive domains handling potentially sensitive data. Inadequate PII protection can lead to:</p>
<p><strong>Legal Consequences</strong>:</p>
<ul>
<li>GDPR fines up to €20M or 4% of global revenue</li>
<li>CCPA penalties up to $7,500 per intentional violation</li>
<li>HIPAA fines from $100 to $50,000 per violation</li>
<li>Class action lawsuits from affected individuals</li>
</ul>
<p><strong>Reputational Damage</strong>:</p>
<ul>
<li>Loss of customer trust</li>
<li>Negative media coverage</li>
<li>Competitive disadvantage</li>
<li>Difficulty attracting new customers</li>
</ul>
<p><strong>Operational Impact</strong>:</p>
<ul>
<li>Mandatory data breach notifications</li>
<li>Regulatory investigations</li>
<li>Service disruptions</li>
<li>Increased insurance premiums</li>
</ul>
<p><strong>Security Risks</strong>:</p>
<ul>
<li>Identity theft</li>
<li>Social engineering attacks</li>
<li>Credential stuffing</li>
<li>Targeted phishing campaigns</li>
</ul>
<h3 id="regulatory-landscape"><a class="header" href="#regulatory-landscape">Regulatory Landscape</a></h3>
<p>OctoLLM operates in a complex regulatory environment with overlapping requirements:</p>
<h4 id="gdpr-general-data-protection-regulation"><a class="header" href="#gdpr-general-data-protection-regulation">GDPR (General Data Protection Regulation)</a></h4>
<p><strong>Scope</strong>: EU/EEA residents, regardless of where processing occurs</p>
<p><strong>Key Requirements</strong>:</p>
<ul>
<li>Lawful basis for processing (consent, contract, legitimate interest)</li>
<li>Data minimization and purpose limitation</li>
<li>Right to access, rectification, erasure, portability</li>
<li>Data protection by design and default</li>
<li>Data Protection Impact Assessments (DPIAs) for high-risk processing</li>
<li>Mandatory breach notification within 72 hours</li>
</ul>
<p><strong>PII Categories</strong>:</p>
<ul>
<li><strong>Personal Data</strong>: Name, email, IP address, location data</li>
<li><strong>Special Categories</strong>: Health data, biometric data, genetic data, racial/ethnic origin</li>
<li><strong>Pseudonymized Data</strong>: Still considered personal if re-identifiable</li>
</ul>
<h4 id="ccpa-california-consumer-privacy-act"><a class="header" href="#ccpa-california-consumer-privacy-act">CCPA (California Consumer Privacy Act)</a></h4>
<p><strong>Scope</strong>: California residents' data collected by businesses meeting thresholds</p>
<p><strong>Key Requirements</strong>:</p>
<ul>
<li>Right to know what data is collected</li>
<li>Right to delete personal information</li>
<li>Right to opt-out of sale of personal information</li>
<li>Right to non-discrimination for exercising rights</li>
<li>Privacy policy and notice at collection</li>
</ul>
<p><strong>PII Categories</strong>:</p>
<ul>
<li><strong>Personal Information</strong>: Identifiers, commercial information, biometric data, internet activity</li>
<li><strong>Sensitive Personal Information</strong>: SSN, driver's license, precise geolocation, account credentials</li>
</ul>
<h4 id="hipaa-health-insurance-portability-and-accountability-act"><a class="header" href="#hipaa-health-insurance-portability-and-accountability-act">HIPAA (Health Insurance Portability and Accountability Act)</a></h4>
<p><strong>Scope</strong>: Protected Health Information (PHI) in healthcare context</p>
<p><strong>Key Requirements</strong>:</p>
<ul>
<li>Administrative, physical, and technical safeguards</li>
<li>Minimum necessary standard</li>
<li>Encryption of ePHI in transit and at rest</li>
<li>Business Associate Agreements (BAAs)</li>
<li>Breach notification requirements</li>
</ul>
<p><strong>PHI Identifiers</strong> (18 types):</p>
<ul>
<li>Names, addresses, dates (except year), phone/fax numbers</li>
<li>Email addresses, SSNs, medical record numbers</li>
<li>Account numbers, certificate/license numbers</li>
<li>URLs, IP addresses, biometric identifiers</li>
<li>Full-face photos, unique identifying characteristics</li>
</ul>
<h3 id="octollm-pii-strategy"><a class="header" href="#octollm-pii-strategy">OctoLLM PII Strategy</a></h3>
<p>OctoLLM implements a comprehensive PII protection strategy across six dimensions:</p>
<h4 id="1-detection-at-all-boundaries"><a class="header" href="#1-detection-at-all-boundaries">1. Detection at All Boundaries</a></h4>
<pre><code class="language-mermaid">graph LR
    subgraph "Input Boundaries"
        API[API Gateway]
        REFLEX[Reflex Layer]
        ORCH[Orchestrator]
    end

    subgraph "Processing"
        ARM[Arms]
        MEM[Memory Stores]
    end

    subgraph "Output Boundaries"
        GUARD[Guardian Arm]
        LOG[Logging]
        DB[Database]
    end

    API --&gt; REFLEX
    REFLEX --&gt; ORCH
    ORCH --&gt; ARM
    ARM --&gt; MEM
    ARM --&gt; GUARD
    GUARD --&gt; LOG
    GUARD --&gt; DB

    style REFLEX fill:#f99,stroke:#333
    style GUARD fill:#f99,stroke:#333
    style LOG fill:#f99,stroke:#333
</code></pre>
<p><strong>Detection Points</strong>:</p>
<ul>
<li><strong>API Gateway</strong>: Initial PII screening before processing</li>
<li><strong>Reflex Layer</strong>: Fast regex-based PII detection (&lt;10ms)</li>
<li><strong>Guardian Arm</strong>: Comprehensive multi-method detection</li>
<li><strong>Logging System</strong>: Pre-log sanitization</li>
<li><strong>Database Layer</strong>: Pre-write validation</li>
<li><strong>Memory Stores</strong>: Collection-level encryption</li>
</ul>
<h4 id="2-automatic-redaction"><a class="header" href="#2-automatic-redaction">2. Automatic Redaction</a></h4>
<p>All detected PII is automatically redacted using configurable strategies:</p>
<p><strong>Redaction Modes</strong>:</p>
<ul>
<li><strong>Type-based</strong>: Replace with <code>[EMAIL-REDACTED]</code>, <code>[SSN-REDACTED]</code></li>
<li><strong>Hash-based</strong>: Replace with deterministic hash for correlation</li>
<li><strong>Structure-preserving</strong>: Maintain format (e.g., <code>XXX-XX-1234</code> for SSN)</li>
<li><strong>Tokenization</strong>: Replace with reversible token for authorized access</li>
</ul>
<h4 id="3-layered-security"><a class="header" href="#3-layered-security">3. Layered Security</a></h4>
<pre><code class="language-python"># Layer 1: Reflex preprocessing (fast)
if has_obvious_pii(text):
    text = quick_redact(text)

# Layer 2: Guardian arm (comprehensive)
safety_result = guardian.check(text, check_types=["pii", "secrets"])
if safety_result.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:
    return BlockedResponse(reason="PII detected")

# Layer 3: Pre-storage validation
if writing_to_database:
    validate_no_pii(data)
    encrypt_sensitive_fields(data)

# Layer 4: Audit logging (obfuscated)
log_event(sanitize_for_logging(event_data))
</code></pre>
<h4 id="4-data-minimization"><a class="header" href="#4-data-minimization">4. Data Minimization</a></h4>
<p>OctoLLM follows the principle of collecting only necessary data:</p>
<p><strong>Collection Policies</strong>:</p>
<ul>
<li>No collection of PII unless operationally necessary</li>
<li>Immediate redaction of incidental PII in user inputs</li>
<li>TTL-based expiration for all collected data</li>
<li>Aggregation over raw data when possible</li>
</ul>
<p><strong>Retention Policies</strong>:</p>
<ul>
<li>Task history: 90 days (anonymized after 30 days)</li>
<li>Audit logs: 1 year (PII-sanitized)</li>
<li>Vector embeddings: 180 days (no raw PII)</li>
<li>Cache data: 24 hours maximum</li>
</ul>
<h4 id="5-encryption-everywhere"><a class="header" href="#5-encryption-everywhere">5. Encryption Everywhere</a></h4>
<p><strong>Data at Rest</strong>:</p>
<ul>
<li>PostgreSQL: Transparent Data Encryption (TDE) + field-level encryption</li>
<li>Qdrant: Collection-level encryption</li>
<li>Redis: Encrypted volumes</li>
<li>Backups: AES-256 encryption</li>
</ul>
<p><strong>Data in Transit</strong>:</p>
<ul>
<li>TLS 1.3 for all inter-component communication</li>
<li>Certificate pinning for external APIs</li>
<li>Mutual TLS (mTLS) within Kubernetes cluster</li>
</ul>
<p><strong>Key Management</strong>:</p>
<ul>
<li>AWS KMS / HashiCorp Vault for key storage</li>
<li>Automatic key rotation (90 days)</li>
<li>Separate keys per environment</li>
<li>Key access audit logging</li>
</ul>
<h4 id="6-privacy-by-design"><a class="header" href="#6-privacy-by-design">6. Privacy by Design</a></h4>
<pre><code class="language-mermaid">graph TD
    subgraph "Design Phase"
        DPIA[Privacy Impact Assessment]
        THREAT[Threat Modeling]
        ARCH[Architecture Review]
    end

    subgraph "Implementation Phase"
        CODE[Privacy-Aware Code]
        TEST[Privacy Testing]
        REVIEW[Security Review]
    end

    subgraph "Deployment Phase"
        CONFIG[Privacy Config]
        MONITOR[Privacy Monitoring]
        AUDIT[Compliance Audit]
    end

    DPIA --&gt; CODE
    THREAT --&gt; CODE
    ARCH --&gt; CODE

    CODE --&gt; CONFIG
    TEST --&gt; CONFIG
    REVIEW --&gt; CONFIG

    CONFIG --&gt; MONITOR
    CONFIG --&gt; AUDIT
</code></pre>
<h3 id="defense-in-depth-approach"><a class="header" href="#defense-in-depth-approach">Defense-in-Depth Approach</a></h3>
<p>OctoLLM implements multiple overlapping layers of PII protection:</p>
<div class="table-wrapper"><table><thead><tr><th>Layer</th><th>Technology</th><th>Latency</th><th>Coverage</th><th>False Positive Rate</th></tr></thead><tbody>
<tr><td><strong>1. API Gateway</strong></td><td>Rate limiting, input validation</td><td>&lt;1ms</td><td>Basic</td><td>&lt;1%</td></tr>
<tr><td><strong>2. Reflex Layer</strong></td><td>Regex patterns</td><td>&lt;10ms</td><td>80%</td><td>2-3%</td></tr>
<tr><td><strong>3. Guardian Arm</strong></td><td>Regex + ML/NER</td><td>&lt;100ms</td><td>95%</td><td>&lt;5%</td></tr>
<tr><td><strong>4. Database</strong></td><td>Schema validation, encryption</td><td>&lt;50ms</td><td>100%</td><td>0%</td></tr>
<tr><td><strong>5. Logging</strong></td><td>Pre-log sanitization</td><td>&lt;5ms</td><td>100%</td><td>0%</td></tr>
<tr><td><strong>6. Audit</strong></td><td>Post-hoc review, anomaly detection</td><td>Async</td><td>100%</td><td>N/A</td></tr>
</tbody></table>
</div>
<p><strong>Effectiveness Metrics</strong>:</p>
<ul>
<li><strong>Detection Rate</strong>: &gt;95% of common PII types</li>
<li><strong>False Positive Rate</strong>: &lt;5% overall</li>
<li><strong>Latency Impact</strong>: &lt;150ms end-to-end</li>
<li><strong>Coverage</strong>: All input/output boundaries</li>
</ul>
<p><strong>Example Multi-Layer Detection</strong>:</p>
<pre><code class="language-python"># Input: "Contact john.doe@example.com (SSN: 123-45-6789)"

# Layer 1: API Gateway
# - No detection (basic validation only)

# Layer 2: Reflex Layer
# - Detects email pattern
# - Detects SSN pattern
# - Returns: "Contact [EMAIL-REDACTED] (SSN: [SSN-REDACTED])"

# Layer 3: Guardian Arm
# - Confirms email detection (high confidence)
# - Confirms SSN detection (high confidence)
# - Risk level: HIGH
# - Action: Block or redact

# Layer 4: Database
# - Schema validation ensures no raw PII in writes
# - Field-level encryption for sensitive columns

# Layer 5: Logging
# - Sanitizes all log messages before writing
# - Replaces any remaining PII with placeholders

# Result: Multiple redundant protections ensure no PII leakage
</code></pre>
<hr />
<h2 id="pii-detection"><a class="header" href="#pii-detection">PII Detection</a></h2>
<h3 id="regex-based-detection"><a class="header" href="#regex-based-detection">Regex-Based Detection</a></h3>
<p>Regex-based detection provides fast, reliable identification of structured PII types with predictable formats.</p>
<h4 id="implementation"><a class="header" href="#implementation">Implementation</a></h4>
<pre><code class="language-python">import re
from typing import List, Tuple, Dict
from enum import Enum
from dataclasses import dataclass

class PIIType(Enum):
    """Enumeration of PII types detected by the system."""
    EMAIL = "email"
    SSN = "ssn"
    PHONE = "phone"
    CREDIT_CARD = "credit_card"
    IP_ADDRESS = "ip_address"
    STREET_ADDRESS = "street_address"
    DATE_OF_BIRTH = "date_of_birth"
    PASSPORT = "passport"
    DRIVERS_LICENSE = "drivers_license"
    MAC_ADDRESS = "mac_address"
    IBAN = "iban"
    PERSON_NAME = "person_name"
    ORGANIZATION = "organization"
    LOCATION = "location"
    US_ZIP_CODE = "us_zip_code"
    UK_POSTCODE = "uk_postcode"
    VEHICLE_VIN = "vehicle_vin"
    MEDICAL_RECORD_NUMBER = "medical_record_number"

# Comprehensive PII patterns with validation
PII_PATTERNS: Dict[PIIType, Dict] = {
    PIIType.EMAIL: {
        "pattern": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
        "validator": "validate_email",
        "risk_level": "medium",
        "description": "Email address"
    },
    PIIType.SSN: {
        "pattern": r'\b\d{3}-\d{2}-\d{4}\b',
        "validator": "validate_ssn",
        "risk_level": "high",
        "description": "US Social Security Number"
    },
    PIIType.PHONE: {
        "pattern": r'\b(?:\+?1[-.\s]?)?\(?([0-9]{3})\)?[-.\s]?([0-9]{3})[-.\s]?([0-9]{4})\b',
        "validator": None,
        "risk_level": "medium",
        "description": "Phone number (US/International)"
    },
    PIIType.CREDIT_CARD: {
        "pattern": r'\b(?:4[0-9]{12}(?:[0-9]{3})?|5[1-5][0-9]{14}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|6(?:011|5[0-9]{2})[0-9]{12}|(?:2131|1800|35\d{3})\d{11})\b',
        "validator": "luhn_check",
        "risk_level": "high",
        "description": "Credit card number (Visa, MC, Amex, Discover)"
    },
    PIIType.IP_ADDRESS: {
        "pattern": r'\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b',
        "validator": "validate_ip",
        "risk_level": "low",
        "description": "IPv4 address"
    },
    PIIType.STREET_ADDRESS: {
        "pattern": r'\b\d+\s+[A-Za-z\s]+(?:Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Court|Ct|Circle|Cir|Way|Place|Pl)\b',
        "validator": None,
        "risk_level": "medium",
        "description": "US street address"
    },
    PIIType.DATE_OF_BIRTH: {
        "pattern": r'\b(?:0?[1-9]|1[0-2])[/-](?:0?[1-9]|[12][0-9]|3[01])[/-](?:19|20)\d{2}\b',
        "validator": "validate_date",
        "risk_level": "high",
        "description": "Date of birth (MM/DD/YYYY or M/D/YYYY)"
    },
    PIIType.PASSPORT: {
        "pattern": r'\b[A-Z]{1,2}[0-9]{6,9}\b',
        "validator": None,
        "risk_level": "high",
        "description": "Passport number (various countries)"
    },
    PIIType.DRIVERS_LICENSE: {
        "pattern": r'\b[A-Z]{1,2}[0-9]{5,8}\b',
        "validator": None,
        "risk_level": "high",
        "description": "Driver's license number"
    },
    PIIType.MAC_ADDRESS: {
        "pattern": r'\b(?:[0-9A-Fa-f]{2}[:-]){5}(?:[0-9A-Fa-f]{2})\b',
        "validator": None,
        "risk_level": "low",
        "description": "MAC address"
    },
    PIIType.IBAN: {
        "pattern": r'\b[A-Z]{2}[0-9]{2}[A-Z0-9]{1,30}\b',
        "validator": "validate_iban",
        "risk_level": "high",
        "description": "International Bank Account Number"
    },
    PIIType.US_ZIP_CODE: {
        "pattern": r'\b\d{5}(?:-\d{4})?\b',
        "validator": None,
        "risk_level": "low",
        "description": "US ZIP code"
    },
    PIIType.UK_POSTCODE: {
        "pattern": r'\b[A-Z]{1,2}[0-9R][0-9A-Z]?\s?[0-9][A-Z]{2}\b',
        "validator": None,
        "risk_level": "low",
        "description": "UK postcode"
    },
    PIIType.VEHICLE_VIN: {
        "pattern": r'\b[A-HJ-NPR-Z0-9]{17}\b',
        "validator": "validate_vin",
        "risk_level": "medium",
        "description": "Vehicle Identification Number"
    },
    PIIType.MEDICAL_RECORD_NUMBER: {
        "pattern": r'\bMRN[:\s]?\d{6,10}\b',
        "validator": None,
        "risk_level": "high",
        "description": "Medical Record Number"
    }
}

@dataclass
class PIIFinding:
    """Represents a single PII detection finding."""
    pii_type: PIIType
    text: str
    start: int
    end: int
    confidence: float = 1.0
    risk_level: str = "medium"
    context: str = ""

    def to_dict(self) -&gt; Dict:
        return {
            "type": self.pii_type.value,
            "text": self.text,
            "start": self.start,
            "end": self.end,
            "confidence": self.confidence,
            "risk_level": self.risk_level,
            "context": self.context
        }

class PIIDetector:
    """Regex-based PII detector with validation."""

    def __init__(self):
        self.compiled_patterns = self._compile_patterns()

    def _compile_patterns(self) -&gt; Dict[PIIType, re.Pattern]:
        """Compile all regex patterns for performance."""
        compiled = {}
        for pii_type, config in PII_PATTERNS.items():
            try:
                compiled[pii_type] = re.compile(
                    config["pattern"],
                    re.IGNORECASE if pii_type in [
                        PIIType.STREET_ADDRESS,
                        PIIType.PERSON_NAME
                    ] else 0
                )
            except re.error as e:
                raise ValueError(f"Invalid regex for {pii_type}: {e}")
        return compiled

    def detect_pii_regex(self, text: str) -&gt; List[PIIFinding]:
        """Detect PII using compiled regex patterns."""
        findings = []

        for pii_type, pattern in self.compiled_patterns.items():
            config = PII_PATTERNS[pii_type]

            for match in pattern.finditer(text):
                matched_text = match.group()

                # Apply validator if configured
                if config["validator"]:
                    validator_func = getattr(self, config["validator"], None)
                    if validator_func and not validator_func(matched_text):
                        continue  # Skip invalid matches

                # Extract context (20 chars before and after)
                context_start = max(0, match.start() - 20)
                context_end = min(len(text), match.end() + 20)
                context = text[context_start:context_end]

                findings.append(PIIFinding(
                    pii_type=pii_type,
                    text=matched_text,
                    start=match.start(),
                    end=match.end(),
                    confidence=0.85,  # Regex confidence
                    risk_level=config["risk_level"],
                    context=context
                ))

        return findings

    # Validation functions

    def validate_email(self, email: str) -&gt; bool:
        """Validate email format."""
        # Basic validation beyond regex
        if email.count('@') != 1:
            return False
        local, domain = email.split('@')
        if len(local) == 0 or len(domain) &lt; 3:
            return False
        if '.' not in domain:
            return False
        return True

    def validate_ssn(self, ssn: str) -&gt; bool:
        """Validate SSN format and invalid patterns."""
        # Remove hyphens
        digits = ssn.replace('-', '')

        # Invalid SSN patterns
        invalid_patterns = [
            '000', '666',  # Area number
            '00',          # Group number
            '0000'         # Serial number
        ]

        # Check for invalid area numbers
        if digits[:3] in ['000', '666'] or digits[:3].startswith('9'):
            return False

        # Check for invalid group/serial
        if digits[3:5] == '00' or digits[5:9] == '0000':
            return False

        # Check for sequential/repeated digits
        if digits == digits[0] * 9:  # e.g., 111-11-1111
            return False

        return True

    def luhn_check(self, card_number: str) -&gt; bool:
        """Validate credit card using Luhn algorithm."""
        # Remove spaces and hyphens
        digits = [int(d) for d in card_number if d.isdigit()]

        if len(digits) &lt; 13 or len(digits) &gt; 19:
            return False

        checksum = 0
        for i, digit in enumerate(reversed(digits)):
            if i % 2 == 1:
                digit *= 2
                if digit &gt; 9:
                    digit -= 9
            checksum += digit

        return checksum % 10 == 0

    def validate_ip(self, ip: str) -&gt; bool:
        """Validate IPv4 address."""
        parts = ip.split('.')
        if len(parts) != 4:
            return False

        try:
            for part in parts:
                num = int(part)
                if num &lt; 0 or num &gt; 255:
                    return False
            return True
        except ValueError:
            return False

    def validate_date(self, date_str: str) -&gt; bool:
        """Validate date format."""
        import datetime

        # Try common date formats
        formats = ['%m/%d/%Y', '%m-%d-%Y', '%m/%d/%y', '%m-%d-%y']

        for fmt in formats:
            try:
                datetime.datetime.strptime(date_str, fmt)
                return True
            except ValueError:
                continue

        return False

    def validate_iban(self, iban: str) -&gt; bool:
        """Validate IBAN using mod-97 algorithm."""
        # Remove spaces
        iban = iban.replace(' ', '').upper()

        # Must be 15-34 characters
        if len(iban) &lt; 15 or len(iban) &gt; 34:
            return False

        # Move first 4 chars to end
        rearranged = iban[4:] + iban[:4]

        # Replace letters with numbers (A=10, B=11, ...)
        numeric = ''
        for char in rearranged:
            if char.isdigit():
                numeric += char
            else:
                numeric += str(ord(char) - ord('A') + 10)

        # Check mod 97
        return int(numeric) % 97 == 1

    def validate_vin(self, vin: str) -&gt; bool:
        """Validate Vehicle Identification Number."""
        if len(vin) != 17:
            return False

        # VIN should not contain I, O, Q
        if any(char in vin.upper() for char in 'IOQ'):
            return False

        # Simple checksum validation (check digit is position 9)
        weights = [8, 7, 6, 5, 4, 3, 2, 10, 0, 9, 8, 7, 6, 5, 4, 3, 2]
        transliteration = {
            'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8,
            'J': 1, 'K': 2, 'L': 3, 'M': 4, 'N': 5, 'P': 7, 'R': 9,
            'S': 2, 'T': 3, 'U': 4, 'V': 5, 'W': 6, 'X': 7, 'Y': 8, 'Z': 9
        }

        total = 0
        for i, char in enumerate(vin.upper()):
            if char.isdigit():
                value = int(char)
            else:
                value = transliteration.get(char, 0)
            total += value * weights[i]

        check_digit = total % 11
        if check_digit == 10:
            check_digit = 'X'
        else:
            check_digit = str(check_digit)

        return vin[8] == check_digit
</code></pre>
<h4 id="pattern-tuning"><a class="header" href="#pattern-tuning">Pattern Tuning</a></h4>
<p><strong>Reducing False Positives</strong>:</p>
<pre><code class="language-python">class PIIDetectorTuned(PIIDetector):
    """Enhanced detector with false positive reduction."""

    def __init__(self):
        super().__init__()
        # Common false positive patterns
        self.false_positive_patterns = {
            PIIType.PHONE: [
                r'\b555-\d{3}-\d{4}\b',  # Fake phone numbers (555 prefix)
                r'\b000-000-0000\b',      # Placeholder
            ],
            PIIType.SSN: [
                r'\b000-00-0000\b',       # Placeholder
                r'\b123-45-6789\b',       # Example SSN
            ],
            PIIType.EMAIL: [
                r'example\.com$',         # Example domain
                r'test\.com$',            # Test domain
                r'localhost$',            # Localhost
            ]
        }

        # Compile false positive patterns
        self.compiled_fp_patterns = {}
        for pii_type, patterns in self.false_positive_patterns.items():
            self.compiled_fp_patterns[pii_type] = [
                re.compile(p, re.IGNORECASE) for p in patterns
            ]

    def is_false_positive(self, finding: PIIFinding) -&gt; bool:
        """Check if a finding is likely a false positive."""
        if finding.pii_type not in self.compiled_fp_patterns:
            return False

        for pattern in self.compiled_fp_patterns[finding.pii_type]:
            if pattern.search(finding.text):
                return True

        return False

    def detect_pii_regex(self, text: str) -&gt; List[PIIFinding]:
        """Detect PII with false positive filtering."""
        findings = super().detect_pii_regex(text)

        # Filter out false positives
        filtered = [f for f in findings if not self.is_false_positive(f)]

        return filtered
</code></pre>
<h3 id="ner-based-detection"><a class="header" href="#ner-based-detection">NER-Based Detection</a></h3>
<p>Named Entity Recognition (NER) provides broader coverage for unstructured PII like names, organizations, and locations.</p>
<h4 id="spacy-implementation"><a class="header" href="#spacy-implementation">spaCy Implementation</a></h4>
<pre><code class="language-python">import spacy
from typing import List, Dict
from spacy.tokens import Doc

class NERPIIDetector:
    """NER-based PII detector using spaCy."""

    def __init__(self, model_name: str = "en_core_web_lg"):
        """Initialize NER detector with spaCy model."""
        try:
            self.nlp = spacy.load(model_name)
        except OSError:
            # Download model if not available
            import subprocess
            subprocess.run(["python", "-m", "spacy", "download", model_name])
            self.nlp = spacy.load(model_name)

        # Map spaCy entity types to PII types
        self.entity_type_mapping = {
            "PERSON": PIIType.PERSON_NAME,
            "ORG": PIIType.ORGANIZATION,
            "GPE": PIIType.LOCATION,       # Geopolitical entity
            "LOC": PIIType.LOCATION,       # Non-GPE locations
            "FAC": PIIType.LOCATION,       # Facilities
            "DATE": PIIType.DATE_OF_BIRTH,  # Could be DOB
            "TIME": None,                   # Usually not PII
            "MONEY": None,                  # Not PII unless with context
            "PRODUCT": None,                # Not PII
            "EVENT": None,                  # Not PII
            "WORK_OF_ART": None,           # Not PII
            "LAW": None,                    # Not PII
            "LANGUAGE": None,               # Not PII
            "NORP": None,                   # Nationalities/religious/political groups
            "CARDINAL": None,               # Numerals
            "ORDINAL": None,                # First, second, etc.
            "QUANTITY": None,               # Measurements
            "PERCENT": None,                # Percentages
        }

    def detect_pii_ner(self, text: str) -&gt; List[PIIFinding]:
        """Detect PII using Named Entity Recognition."""
        findings = []

        # Process text with spaCy
        doc: Doc = self.nlp(text)

        for ent in doc.ents:
            # Map entity type to PII type
            pii_type = self.entity_type_mapping.get(ent.label_)

            if pii_type is None:
                continue  # Not a PII-relevant entity

            # Extract context
            context_start = max(0, ent.start_char - 20)
            context_end = min(len(text), ent.end_char + 20)
            context = text[context_start:context_end]

            # Determine risk level based on entity type
            risk_level = self._get_risk_level(pii_type, ent)

            findings.append(PIIFinding(
                pii_type=pii_type,
                text=ent.text,
                start=ent.start_char,
                end=ent.end_char,
                confidence=self._estimate_confidence(ent),
                risk_level=risk_level,
                context=context
            ))

        return findings

    def _get_risk_level(self, pii_type: PIIType, entity) -&gt; str:
        """Determine risk level for NER-detected entity."""
        if pii_type == PIIType.PERSON_NAME:
            # Full names are higher risk than single names
            if len(entity.text.split()) &gt;= 2:
                return "high"
            else:
                return "medium"
        elif pii_type == PIIType.ORGANIZATION:
            return "low"
        elif pii_type == PIIType.LOCATION:
            # Specific addresses are higher risk
            if "street" in entity.text.lower() or "road" in entity.text.lower():
                return "high"
            else:
                return "low"
        elif pii_type == PIIType.DATE_OF_BIRTH:
            return "high"
        else:
            return "medium"

    def _estimate_confidence(self, entity) -&gt; float:
        """Estimate confidence based on entity properties."""
        # Base confidence from spaCy
        confidence = 0.75

        # Adjust based on entity length (longer entities more likely correct)
        if len(entity.text.split()) &gt;= 2:
            confidence += 0.10

        # Adjust based on entity type
        if entity.label_ in ["PERSON", "ORG", "GPE"]:
            confidence += 0.05

        return min(confidence, 1.0)
</code></pre>
<h4 id="custom-ner-training"><a class="header" href="#custom-ner-training">Custom NER Training</a></h4>
<p>For domain-specific PII detection, train a custom NER model:</p>
<pre><code class="language-python">import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random

class CustomNERTrainer:
    """Train custom NER model for domain-specific PII."""

    def __init__(self, base_model: str = "en_core_web_sm"):
        """Initialize trainer with base model."""
        self.nlp = spacy.load(base_model)

        # Add custom entity labels if not present
        ner = self.nlp.get_pipe("ner")
        for label in ["API_KEY", "AUTH_TOKEN", "INTERNAL_ID", "CUSTOMER_ID"]:
            ner.add_label(label)

    def train(self, training_data: List[Tuple[str, Dict]], n_iter: int = 30):
        """Train NER model on custom data."""
        # Format: [("text", {"entities": [(start, end, label), ...]}), ...]

        # Disable other pipeline components
        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != "ner"]
        with self.nlp.disable_pipes(*other_pipes):
            # Training loop
            optimizer = self.nlp.create_optimizer()

            for iteration in range(n_iter):
                random.shuffle(training_data)
                losses = {}

                # Batch training
                batches = minibatch(training_data, size=compounding(4.0, 32.0, 1.001))
                for batch in batches:
                    examples = []
                    for text, annotations in batch:
                        doc = self.nlp.make_doc(text)
                        example = Example.from_dict(doc, annotations)
                        examples.append(example)

                    self.nlp.update(examples, drop=0.5, losses=losses, sgd=optimizer)

                print(f"Iteration {iteration + 1}/{n_iter}, Loss: {losses['ner']:.4f}")

    def save(self, output_dir: str):
        """Save trained model."""
        self.nlp.to_disk(output_dir)

# Example training data
TRAINING_DATA = [
    ("User API key is sk-abc123xyz456", {
        "entities": [(17, 33, "API_KEY")]
    }),
    ("Customer ID: CUST-12345 made a purchase", {
        "entities": [(14, 24, "CUSTOMER_ID")]
    }),
    ("Auth token: Bearer eyJhbGc...", {
        "entities": [(12, 27, "AUTH_TOKEN")]
    }),
]

# Train custom model
# trainer = CustomNERTrainer()
# trainer.train(TRAINING_DATA, n_iter=30)
# trainer.save("./models/custom_pii_ner")
</code></pre>
<h3 id="combined-detection-strategy"><a class="header" href="#combined-detection-strategy">Combined Detection Strategy</a></h3>
<p>Combine regex and NER for comprehensive PII detection:</p>
<pre><code class="language-python">from typing import List, Set
from dataclasses import dataclass

@dataclass
class DetectionConfig:
    """Configuration for PII detection."""
    use_regex: bool = True
    use_ner: bool = True
    min_confidence: float = 0.7
    deduplicate: bool = True
    false_positive_filter: bool = True

class CombinedPIIDetector:
    """Combined regex + NER PII detector."""

    def __init__(self, config: DetectionConfig = None):
        self.config = config or DetectionConfig()

        # Initialize detectors
        if self.config.use_regex:
            self.regex_detector = PIIDetectorTuned()

        if self.config.use_ner:
            self.ner_detector = NERPIIDetector()

    def detect(self, text: str) -&gt; List[PIIFinding]:
        """Detect PII using multiple methods."""
        all_findings = []

        # Regex detection (fast, high precision)
        if self.config.use_regex:
            regex_findings = self.regex_detector.detect_pii_regex(text)
            all_findings.extend(regex_findings)

        # NER detection (slower, broader coverage)
        if self.config.use_ner:
            ner_findings = self.ner_detector.detect_pii_ner(text)
            all_findings.extend(ner_findings)

        # Deduplicate overlapping findings
        if self.config.deduplicate:
            all_findings = self.deduplicate_findings(all_findings)

        # Filter by confidence threshold
        all_findings = [
            f for f in all_findings
            if f.confidence &gt;= self.config.min_confidence
        ]

        # Sort by position
        all_findings.sort(key=lambda f: f.start)

        return all_findings

    def deduplicate_findings(self, findings: List[PIIFinding]) -&gt; List[PIIFinding]:
        """Remove overlapping findings, keeping higher confidence."""
        if not findings:
            return []

        # Sort by start position, then by confidence (descending)
        sorted_findings = sorted(
            findings,
            key=lambda f: (f.start, -f.confidence)
        )

        result = []
        for finding in sorted_findings:
            # Check for overlap with existing findings
            overlaps = False
            for existing in result:
                if self._overlaps(finding, existing):
                    # Keep the higher confidence finding
                    if finding.confidence &gt; existing.confidence:
                        result.remove(existing)
                        result.append(finding)
                    overlaps = True
                    break

            if not overlaps:
                result.append(finding)

        return result

    def _overlaps(self, f1: PIIFinding, f2: PIIFinding) -&gt; bool:
        """Check if two findings overlap."""
        return (
            (f1.start &gt;= f2.start and f1.start &lt; f2.end) or
            (f1.end &gt; f2.start and f1.end &lt;= f2.end) or
            (f1.start &lt;= f2.start and f1.end &gt;= f2.end)
        )

    def get_statistics(self, findings: List[PIIFinding]) -&gt; Dict:
        """Generate detection statistics."""
        if not findings:
            return {
                "total_findings": 0,
                "by_type": {},
                "by_risk_level": {},
                "average_confidence": 0.0
            }

        by_type = {}
        by_risk = {}

        for finding in findings:
            # Count by type
            type_key = finding.pii_type.value
            by_type[type_key] = by_type.get(type_key, 0) + 1

            # Count by risk level
            by_risk[finding.risk_level] = by_risk.get(finding.risk_level, 0) + 1

        avg_confidence = sum(f.confidence for f in findings) / len(findings)

        return {
            "total_findings": len(findings),
            "by_type": by_type,
            "by_risk_level": by_risk,
            "average_confidence": round(avg_confidence, 3)
        }
</code></pre>
<h4 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Latency (100 words)</th><th>Precision</th><th>Recall</th><th>Coverage</th></tr></thead><tbody>
<tr><td><strong>Regex Only</strong></td><td>~5ms</td><td>95%</td><td>80%</td><td>Structured PII</td></tr>
<tr><td><strong>NER Only</strong></td><td>~50ms</td><td>75%</td><td>90%</td><td>Unstructured PII</td></tr>
<tr><td><strong>Combined</strong></td><td>~55ms</td><td>90%</td><td>95%</td><td>All PII types</td></tr>
</tbody></table>
</div>
<p><strong>Recommendation</strong>: Use combined detection for comprehensive coverage, regex-only for latency-sensitive paths.</p>
<h3 id="custom-pii-types"><a class="header" href="#custom-pii-types">Custom PII Types</a></h3>
<p>Define organization-specific PII types:</p>
<pre><code class="language-python">class OrganizationPIIDetector(CombinedPIIDetector):
    """Detector with custom organization-specific PII patterns."""

    def __init__(self, config: DetectionConfig = None):
        super().__init__(config)

        # Add custom patterns to regex detector
        if self.config.use_regex:
            self._add_custom_patterns()

    def _add_custom_patterns(self):
        """Add organization-specific PII patterns."""
        custom_patterns = {
            PIIType.CUSTOMER_ID: {
                "pattern": r'\bCUST-\d{5,10}\b',
                "validator": None,
                "risk_level": "high",
                "description": "Internal customer ID"
            },
            PIIType.EMPLOYEE_ID: {
                "pattern": r'\bEMP-\d{5}\b',
                "validator": None,
                "risk_level": "high",
                "description": "Employee ID"
            },
            PIIType.ACCOUNT_NUMBER: {
                "pattern": r'\bACCT-\d{8,12}\b',
                "validator": None,
                "risk_level": "high",
                "description": "Account number"
            },
            PIIType.INTERNAL_IP: {
                "pattern": r'\b(?:10\.|172\.(?:1[6-9]|2[0-9]|3[01])\.|192\.168\.)\d{1,3}\.\d{1,3}\b',
                "validator": "validate_ip",
                "risk_level": "medium",
                "description": "Internal IP address (RFC 1918)"
            }
        }

        # Update PII_PATTERNS with custom types
        PII_PATTERNS.update(custom_patterns)

        # Recompile patterns
        self.regex_detector.compiled_patterns = self.regex_detector._compile_patterns()

# Extend PIIType enum
class CustomPIIType(Enum):
    CUSTOMER_ID = "customer_id"
    EMPLOYEE_ID = "employee_id"
    ACCOUNT_NUMBER = "account_number"
    INTERNAL_IP = "internal_ip"
    PROJECT_CODE = "project_code"
    AUTHORIZATION_CODE = "authorization_code"
</code></pre>
<h3 id="detection-accuracy"><a class="header" href="#detection-accuracy">Detection Accuracy</a></h3>
<h4 id="benchmark-results"><a class="header" href="#benchmark-results">Benchmark Results</a></h4>
<p>Testing on a dataset of 10,000 documents with manually labeled PII:</p>
<div class="table-wrapper"><table><thead><tr><th>PII Type</th><th>True Positives</th><th>False Positives</th><th>False Negatives</th><th>Precision</th><th>Recall</th><th>F1 Score</th></tr></thead><tbody>
<tr><td>Email</td><td>9,523</td><td>142</td><td>335</td><td>98.5%</td><td>96.6%</td><td>97.5%</td></tr>
<tr><td>Phone</td><td>8,891</td><td>234</td><td>875</td><td>97.4%</td><td>91.0%</td><td>94.1%</td></tr>
<tr><td>SSN</td><td>1,456</td><td>23</td><td>44</td><td>98.4%</td><td>97.1%</td><td>97.7%</td></tr>
<tr><td>Credit Card</td><td>892</td><td>12</td><td>8</td><td>98.7%</td><td>99.1%</td><td>98.9%</td></tr>
<tr><td>IP Address</td><td>5,672</td><td>421</td><td>328</td><td>93.1%</td><td>94.5%</td><td>93.8%</td></tr>
<tr><td>Street Address</td><td>2,341</td><td>678</td><td>559</td><td>77.5%</td><td>80.7%</td><td>79.1%</td></tr>
<tr><td>Person Name</td><td>12,453</td><td>1,892</td><td>2,547</td><td>86.8%</td><td>83.0%</td><td>84.9%</td></tr>
<tr><td><strong>Overall</strong></td><td><strong>41,228</strong></td><td><strong>3,402</strong></td><td><strong>4,696</strong></td><td><strong>92.4%</strong></td><td><strong>89.8%</strong></td><td><strong>91.1%</strong></td></tr>
</tbody></table>
</div>
<p><strong>Key Insights</strong>:</p>
<ul>
<li>Structured PII (SSN, credit cards) &gt;98% precision</li>
<li>Unstructured PII (names, addresses) 75-87% precision</li>
<li>Combined approach achieves 91% F1 score</li>
<li>False positive rate &lt;7.6% overall</li>
</ul>
<h4 id="continuous-improvement"><a class="header" href="#continuous-improvement">Continuous Improvement</a></h4>
<pre><code class="language-python">class PIIDetectorWithLearning(CombinedPIIDetector):
    """PII detector with feedback loop for continuous improvement."""

    def __init__(self, config: DetectionConfig = None):
        super().__init__(config)
        self.feedback_log = []

    def record_feedback(
        self,
        text: str,
        finding: PIIFinding,
        is_correct: bool,
        user_id: str = None
    ):
        """Record user feedback on detection accuracy."""
        self.feedback_log.append({
            "timestamp": datetime.utcnow().isoformat(),
            "text": text,
            "finding": finding.to_dict(),
            "is_correct": is_correct,
            "user_id": user_id
        })

    def analyze_feedback(self) -&gt; Dict:
        """Analyze feedback to identify improvement areas."""
        if not self.feedback_log:
            return {"message": "No feedback data"}

        correct = sum(1 for f in self.feedback_log if f["is_correct"])
        total = len(self.feedback_log)
        accuracy = correct / total if total &gt; 0 else 0

        # Identify problematic PII types
        false_positives = {}
        for feedback in self.feedback_log:
            if not feedback["is_correct"]:
                pii_type = feedback["finding"]["type"]
                false_positives[pii_type] = false_positives.get(pii_type, 0) + 1

        return {
            "total_feedback": total,
            "accuracy": round(accuracy, 3),
            "false_positives_by_type": false_positives,
            "recommendations": self._generate_recommendations(false_positives)
        }

    def _generate_recommendations(self, false_positives: Dict) -&gt; List[str]:
        """Generate recommendations based on feedback."""
        recommendations = []

        for pii_type, count in sorted(
            false_positives.items(),
            key=lambda x: x[1],
            reverse=True
        ):
            if count &gt;= 10:
                recommendations.append(
                    f"Review and tune {pii_type} detection patterns ({count} false positives)"
                )

        return recommendations
</code></pre>
<hr />
<h2 id="automatic-redaction"><a class="header" href="#automatic-redaction">Automatic Redaction</a></h2>
<h3 id="redaction-strategies"><a class="header" href="#redaction-strategies">Redaction Strategies</a></h3>
<p>OctoLLM supports multiple redaction strategies for different use cases:</p>
<h4 id="strategy-1-type-based-redaction"><a class="header" href="#strategy-1-type-based-redaction">Strategy 1: Type-Based Redaction</a></h4>
<p>Replace PII with type indicator:</p>
<pre><code class="language-python">class TypeBasedRedactor:
    """Redact PII by replacing with type labels."""

    def redact(self, text: str, findings: List[PIIFinding]) -&gt; str:
        """Redact PII with type labels."""
        # Sort findings in reverse order to maintain positions
        sorted_findings = sorted(findings, key=lambda f: f.start, reverse=True)

        result = text
        for finding in sorted_findings:
            redaction = f"[{finding.pii_type.value.upper()}-REDACTED]"
            result = result[:finding.start] + redaction + result[finding.end:]

        return result

# Example
# Input: "Contact john.doe@example.com or call 555-123-4567"
# Output: "Contact [EMAIL-REDACTED] or call [PHONE-REDACTED]"
</code></pre>
<h4 id="strategy-2-hash-based-redaction"><a class="header" href="#strategy-2-hash-based-redaction">Strategy 2: Hash-Based Redaction</a></h4>
<p>Replace with deterministic hash for correlation:</p>
<pre><code class="language-python">import hashlib

class HashBasedRedactor:
    """Redact PII with deterministic hashes for correlation."""

    def __init__(self, salt: str = ""):
        self.salt = salt

    def redact(self, text: str, findings: List[PIIFinding]) -&gt; str:
        """Redact PII with hashes."""
        sorted_findings = sorted(findings, key=lambda f: f.start, reverse=True)

        result = text
        for finding in sorted_findings:
            # Generate deterministic hash
            hash_input = finding.text + self.salt
            hash_val = hashlib.sha256(hash_input.encode()).hexdigest()[:12]

            redaction = f"[{finding.pii_type.value.upper()}:{hash_val}]"
            result = result[:finding.start] + redaction + result[finding.end:]

        return result

# Example
# Input: "User john.doe@example.com made a purchase"
# Output: "User [EMAIL:a3f2b5c8d1e9] made a purchase"
# Same email always hashes to same value (enables correlation)
</code></pre>
<h4 id="strategy-3-mask-based-redaction"><a class="header" href="#strategy-3-mask-based-redaction">Strategy 3: Mask-Based Redaction</a></h4>
<p>Replace with asterisks while preserving length:</p>
<pre><code class="language-python">class MaskBasedRedactor:
    """Redact PII with asterisks, preserving length."""

    def redact(self, text: str, findings: List[PIIFinding]) -&gt; str:
        """Redact PII with asterisks."""
        sorted_findings = sorted(findings, key=lambda f: f.start, reverse=True)

        result = text
        for finding in sorted_findings:
            # Replace with asterisks
            redaction = "*" * len(finding.text)
            result = result[:finding.start] + redaction + result[finding.end:]

        return result

# Example
# Input: "SSN: 123-45-6789"
# Output: "SSN: ***********"
</code></pre>
<h4 id="strategy-4-tokenization"><a class="header" href="#strategy-4-tokenization">Strategy 4: Tokenization</a></h4>
<p>Replace with reversible tokens (for authorized users):</p>
<pre><code class="language-python">from cryptography.fernet import Fernet
import base64
import json

class TokenizationRedactor:
    """Redact PII with reversible tokens."""

    def __init__(self, encryption_key: bytes = None):
        if encryption_key is None:
            encryption_key = Fernet.generate_key()
        self.cipher = Fernet(encryption_key)
        self.token_map = {}  # Store token -&gt; original mapping

    def redact(self, text: str, findings: List[PIIFinding]) -&gt; str:
        """Redact PII with encrypted tokens."""
        sorted_findings = sorted(findings, key=lambda f: f.start, reverse=True)

        result = text
        for finding in sorted_findings:
            # Create encrypted token
            token_data = json.dumps({
                "type": finding.pii_type.value,
                "value": finding.text
            })
            encrypted = self.cipher.encrypt(token_data.encode())
            token = base64.urlsafe_b64encode(encrypted).decode()[:16]

            redaction = f"[TOKEN:{token}]"
            self.token_map[token] = finding.text

            result = result[:finding.start] + redaction + result[finding.end:]

        return result

    def detokenize(self, redacted_text: str, token: str) -&gt; str:
        """Restore original value from token (requires authorization)."""
        if token not in self.token_map:
            raise ValueError(f"Invalid token: {token}")

        return redacted_text.replace(f"[TOKEN:{token}]", self.token_map[token])

# Example
# Input: "Email: john.doe@example.com"
# Output: "Email: [TOKEN:a3F2b5C8d1E9]"
# Can be reversed with proper authorization
</code></pre>
<h3 id="structure-preserving-redaction"><a class="header" href="#structure-preserving-redaction">Structure-Preserving Redaction</a></h3>
<p>Maintain readability by preserving structure:</p>
<pre><code class="language-python">class StructurePreservingRedactor:
    """Redact PII while preserving text structure."""

    def redact(self, text: str, findings: List[PIIFinding]) -&gt; str:
        """Redact PII with structure preservation."""
        sorted_findings = sorted(findings, key=lambda f: f.start, reverse=True)

        result = text
        for finding in sorted_findings:
            redaction = self._generate_structural_redaction(finding)
            result = result[:finding.start] + redaction + result[finding.end:]

        return result

    def _generate_structural_redaction(self, finding: PIIFinding) -&gt; str:
        """Generate structure-preserving redaction."""
        if finding.pii_type == PIIType.EMAIL:
            # Preserve first char of local part and domain
            parts = finding.text.split('@')
            if len(parts) == 2:
                local, domain = parts
                return f"{local[0]}***@{domain}"
            return "[EMAIL-REDACTED]"

        elif finding.pii_type == PIIType.PHONE:
            # Preserve last 4 digits
            digits = ''.join(c for c in finding.text if c.isdigit())
            if len(digits) &gt;= 4:
                return f"XXX-XXX-{digits[-4:]}"
            return "[PHONE-REDACTED]"

        elif finding.pii_type == PIIType.SSN:
            # Preserve last 4 digits
            digits = ''.join(c for c in finding.text if c.isdigit())
            if len(digits) == 9:
                return f"XXX-XX-{digits[-4:]}"
            return "[SSN-REDACTED]"

        elif finding.pii_type == PIIType.CREDIT_CARD:
            # Preserve last 4 digits
            digits = ''.join(c for c in finding.text if c.isdigit())
            if len(digits) &gt;= 4:
                return f"****-****-****-{digits[-4:]}"
            return "[CC-REDACTED]"

        elif finding.pii_type == PIIType.PERSON_NAME:
            # Preserve first name initial and last name initial
            parts = finding.text.split()
            if len(parts) &gt;= 2:
                return f"{parts[0][0]}. {parts[-1][0]}."
            elif len(parts) == 1:
                return f"{parts[0][0]}."
            return "[NAME-REDACTED]"

        elif finding.pii_type == PIIType.STREET_ADDRESS:
            # Preserve street type
            import re
            street_type_pattern = r'(Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Court|Ct)$'
            match = re.search(street_type_pattern, finding.text, re.IGNORECASE)
            if match:
                return f"[ADDRESS] {match.group()}"
            return "[ADDRESS-REDACTED]"

        else:
            # Default: type-based redaction
            return f"[{finding.pii_type.value.upper()}-REDACTED]"

# Example
# Input: "Contact John Doe at john.doe@example.com or 555-123-4567"
# Output: "Contact J. D. at j***@example.com or XXX-XXX-4567"
</code></pre>
<h3 id="reversible-redaction"><a class="header" href="#reversible-redaction">Reversible Redaction</a></h3>
<p>Implement secure reversible redaction for audit purposes:</p>
<pre><code class="language-python">from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2
import os
import json
import base64

class ReversibleRedactor:
    """Secure reversible PII redaction system."""

    def __init__(self, master_password: str, salt: bytes = None):
        """Initialize with master password."""
        if salt is None:
            salt = os.urandom(16)

        self.salt = salt

        # Derive encryption key from password
        kdf = PBKDF2(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000
        )
        self.key = kdf.derive(master_password.encode())
        self.cipher = AESGCM(self.key)

    def redact_with_encryption(
        self,
        text: str,
        findings: List[PIIFinding],
        metadata: Dict = None
    ) -&gt; Tuple[str, Dict]:
        """Redact PII with encrypted storage for reversal."""
        sorted_findings = sorted(findings, key=lambda f: f.start, reverse=True)

        redaction_map = {}
        result = text

        for i, finding in enumerate(sorted_findings):
            # Generate unique redaction ID
            redaction_id = f"REDACTED_{i:04d}"

            # Encrypt the original value
            nonce = os.urandom(12)
            original_data = json.dumps({
                "value": finding.text,
                "type": finding.pii_type.value,
                "position": finding.start,
                "metadata": metadata or {}
            })

            ciphertext = self.cipher.encrypt(
                nonce,
                original_data.encode(),
                None  # No additional authenticated data
            )

            # Store encrypted value
            redaction_map[redaction_id] = {
                "nonce": base64.b64encode(nonce).decode(),
                "ciphertext": base64.b64encode(ciphertext).decode(),
                "type": finding.pii_type.value
            }

            # Replace in text
            replacement = f"[{redaction_id}]"
            result = result[:finding.start] + replacement + result[finding.end:]

        return result, redaction_map

    def deredact(
        self,
        redacted_text: str,
        redaction_map: Dict,
        redaction_ids: List[str] = None
    ) -&gt; str:
        """Restore original values from redacted text."""
        if redaction_ids is None:
            redaction_ids = list(redaction_map.keys())

        result = redacted_text

        for redaction_id in redaction_ids:
            if redaction_id not in redaction_map:
                continue

            # Decrypt the original value
            encrypted_data = redaction_map[redaction_id]
            nonce = base64.b64decode(encrypted_data["nonce"])
            ciphertext = base64.b64decode(encrypted_data["ciphertext"])

            try:
                decrypted = self.cipher.decrypt(nonce, ciphertext, None)
                original_data = json.loads(decrypted.decode())

                # Replace in text
                result = result.replace(
                    f"[{redaction_id}]",
                    original_data["value"]
                )
            except Exception as e:
                # Decryption failed (wrong key or tampered data)
                raise ValueError(f"Failed to decrypt {redaction_id}: {e}")

        return result

    def partial_deredact(
        self,
        redacted_text: str,
        redaction_map: Dict,
        allowed_types: List[PIIType]
    ) -&gt; str:
        """Restore only specific PII types (selective de-redaction)."""
        allowed_type_values = [t.value for t in allowed_types]

        # Filter redaction IDs by allowed types
        redaction_ids = [
            rid for rid, data in redaction_map.items()
            if data["type"] in allowed_type_values
        ]

        return self.deredact(redacted_text, redaction_map, redaction_ids)

# Example usage
# detector = CombinedPIIDetector()
# redactor = ReversibleRedactor(master_password="secure_password_here")
#
# text = "Contact John Doe at john.doe@example.com or SSN 123-45-6789"
# findings = detector.detect(text)
#
# redacted, redaction_map = redactor.redact_with_encryption(text, findings)
# # Output: "Contact [REDACTED_0000] at [REDACTED_0001] or SSN [REDACTED_0002]"
#
# # Later, with proper authorization:
# original = redactor.deredact(redacted, redaction_map)
# # Output: "Contact John Doe at john.doe@example.com or SSN 123-45-6789"
#
# # Or partial restoration:
# partial = redactor.partial_deredact(redacted, redaction_map, [PIIType.EMAIL])
# # Output: "Contact [REDACTED_0000] at john.doe@example.com or SSN [REDACTED_0002]"
</code></pre>
<h3 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h3>
<h4 id="batch-processing"><a class="header" href="#batch-processing">Batch Processing</a></h4>
<p>Process multiple documents efficiently:</p>
<pre><code class="language-python">class BatchRedactor:
    """Optimized batch redaction processor."""

    def __init__(self, detector: CombinedPIIDetector, redactor):
        self.detector = detector
        self.redactor = redactor

    def redact_batch(
        self,
        texts: List[str],
        batch_size: int = 100,
        parallel: bool = True
    ) -&gt; List[str]:
        """Redact multiple texts efficiently."""
        if not parallel:
            return [self._redact_single(text) for text in texts]

        # Parallel processing
        from concurrent.futures import ThreadPoolExecutor, as_completed

        results = [None] * len(texts)
        with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
            # Submit all tasks
            future_to_index = {
                executor.submit(self._redact_single, text): i
                for i, text in enumerate(texts)
            }

            # Collect results
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    results[index] = f"[ERROR: {str(e)}]"

        return results

    def _redact_single(self, text: str) -&gt; str:
        """Redact single text."""
        findings = self.detector.detect(text)
        return self.redactor.redact(text, findings)

    def get_statistics(self, texts: List[str]) -&gt; Dict:
        """Generate batch statistics."""
        total_findings = 0
        total_chars_redacted = 0

        for text in texts:
            findings = self.detector.detect(text)
            total_findings += len(findings)
            total_chars_redacted += sum(len(f.text) for f in findings)

        return {
            "total_documents": len(texts),
            "total_findings": total_findings,
            "average_findings_per_doc": round(total_findings / len(texts), 2) if texts else 0,
            "total_chars_redacted": total_chars_redacted,
            "average_chars_per_finding": round(total_chars_redacted / total_findings, 2) if total_findings &gt; 0 else 0
        }

# Example
# batch_redactor = BatchRedactor(
#     detector=CombinedPIIDetector(),
#     redactor=StructurePreservingRedactor()
# )
#
# texts = [
#     "User john.doe@example.com logged in",
#     "SSN 123-45-6789 belongs to Jane Smith",
#     # ... 1000 more documents
# ]
#
# redacted_texts = batch_redactor.redact_batch(texts, parallel=True)
# stats = batch_redactor.get_statistics(texts)
</code></pre>
<h4 id="caching"><a class="header" href="#caching">Caching</a></h4>
<p>Cache regex compilation and NER models:</p>
<pre><code class="language-python">from functools import lru_cache
import pickle

class CachedPIIDetector(CombinedPIIDetector):
    """PII detector with caching optimizations."""

    def __init__(self, config: DetectionConfig = None):
        super().__init__(config)
        self._pattern_cache = {}
        self._result_cache = {}

    @lru_cache(maxsize=10000)
    def detect_cached(self, text: str) -&gt; Tuple[PIIFinding, ...]:
        """Detect PII with result caching."""
        findings = self.detect(text)
        # Return tuple for hashability
        return tuple(findings)

    def clear_cache(self):
        """Clear cached results."""
        self.detect_cached.cache_clear()
        self._result_cache.clear()

    def get_cache_stats(self) -&gt; Dict:
        """Get cache statistics."""
        cache_info = self.detect_cached.cache_info()
        return {
            "hits": cache_info.hits,
            "misses": cache_info.misses,
            "size": cache_info.currsize,
            "max_size": cache_info.maxsize,
            "hit_rate": round(cache_info.hits / (cache_info.hits + cache_info.misses), 3) if (cache_info.hits + cache_info.misses) &gt; 0 else 0
        }
</code></pre>
<h4 id="incremental-processing"><a class="header" href="#incremental-processing">Incremental Processing</a></h4>
<p>Process streaming data efficiently:</p>
<pre><code class="language-python">class StreamingRedactor:
    """Redactor for streaming/incremental text processing."""

    def __init__(self, detector: CombinedPIIDetector, redactor, chunk_size: int = 1000):
        self.detector = detector
        self.redactor = redactor
        self.chunk_size = chunk_size
        self.buffer = ""
        self.findings_buffer = []

    def process_chunk(self, chunk: str) -&gt; str:
        """Process a chunk of text incrementally."""
        self.buffer += chunk

        # Only process if buffer exceeds chunk size
        if len(self.buffer) &lt; self.chunk_size:
            return ""

        # Detect PII in buffer
        findings = self.detector.detect(self.buffer)

        # Redact
        redacted = self.redactor.redact(self.buffer, findings)

        # Reset buffer
        self.buffer = ""
        self.findings_buffer.extend(findings)

        return redacted

    def flush(self) -&gt; str:
        """Process remaining buffer."""
        if not self.buffer:
            return ""

        findings = self.detector.detect(self.buffer)
        redacted = self.redactor.redact(self.buffer, findings)

        self.buffer = ""
        self.findings_buffer.extend(findings)

        return redacted

    def get_findings(self) -&gt; List[PIIFinding]:
        """Get all findings from processed text."""
        return self.findings_buffer

# Example
# streaming_redactor = StreamingRedactor(
#     detector=CombinedPIIDetector(),
#     redactor=TypeBasedRedactor()
# )
#
# # Process streaming data
# with open("large_file.txt", "r") as f:
#     for line in f:
#         redacted_chunk = streaming_redactor.process_chunk(line)
#         if redacted_chunk:
#             print(redacted_chunk)
#
# # Process remaining buffer
# final_chunk = streaming_redactor.flush()
# if final_chunk:
#     print(final_chunk)
</code></pre>
<p><strong>Performance Benchmarks</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Throughput (docs/sec)</th><th>Latency (ms)</th><th>Memory (MB)</th></tr></thead><tbody>
<tr><td>Single-threaded</td><td>50</td><td>20</td><td>100</td></tr>
<tr><td>Batch (100 docs)</td><td>500</td><td>2 (avg)</td><td>150</td></tr>
<tr><td>Parallel (8 cores)</td><td>2,000</td><td>8 (avg)</td><td>400</td></tr>
<tr><td>Streaming</td><td>1,000</td><td>1 (chunk)</td><td>50</td></tr>
<tr><td>Cached</td><td>5,000</td><td>0.2 (cache hit)</td><td>200</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="data-sanitization"><a class="header" href="#data-sanitization">Data Sanitization</a></h2>
<h3 id="sanitization-for-logging"><a class="header" href="#sanitization-for-logging">Sanitization for Logging</a></h3>
<p>Ensure logs never contain PII:</p>
<pre><code class="language-python">from typing import Any, Dict
import logging
import structlog

class PIISanitizingLogger:
    """Logger with automatic PII sanitization."""

    def __init__(self, detector: CombinedPIIDetector, redactor):
        self.detector = detector
        self.redactor = redactor

        # Configure structlog with sanitization processor
        structlog.configure(
            processors=[
                self._sanitize_event,
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.StackInfoRenderer(),
                structlog.dev.ConsoleRenderer()
            ],
            context_class=dict,
            logger_factory=structlog.stdlib.LoggerFactory(),
            cache_logger_on_first_use=True,
        )

        self.logger = structlog.get_logger()

    def _sanitize_event(self, logger, method_name, event_dict):
        """Processor to sanitize log events."""
        # Sanitize all string values in event
        sanitized = {}
        for key, value in event_dict.items():
            if isinstance(value, str):
                sanitized[key] = self._sanitize_value(value)
            elif isinstance(value, dict):
                sanitized[key] = self._sanitize_dict(value)
            elif isinstance(value, (list, tuple)):
                sanitized[key] = self._sanitize_list(value)
            else:
                sanitized[key] = value

        return sanitized

    def _sanitize_value(self, value: str) -&gt; str:
        """Sanitize a single string value."""
        findings = self.detector.detect(value)
        if not findings:
            return value
        return self.redactor.redact(value, findings)

    def _sanitize_dict(self, data: Dict) -&gt; Dict:
        """Recursively sanitize dictionary."""
        return {
            k: self._sanitize_value(v) if isinstance(v, str)
            else self._sanitize_dict(v) if isinstance(v, dict)
            else self._sanitize_list(v) if isinstance(v, (list, tuple))
            else v
            for k, v in data.items()
        }

    def _sanitize_list(self, data: list) -&gt; list:
        """Sanitize list of values."""
        return [
            self._sanitize_value(item) if isinstance(item, str)
            else self._sanitize_dict(item) if isinstance(item, dict)
            else item
            for item in data
        ]

    def info(self, message: str, **kwargs):
        """Log info message with sanitization."""
        self.logger.info(message, **kwargs)

    def warning(self, message: str, **kwargs):
        """Log warning message with sanitization."""
        self.logger.warning(message, **kwargs)

    def error(self, message: str, **kwargs):
        """Log error message with sanitization."""
        self.logger.error(message, **kwargs)

# Example usage
# logger = PIISanitizingLogger(
#     detector=CombinedPIIDetector(),
#     redactor=TypeBasedRedactor()
# )
#
# # This will automatically redact PII before logging
# logger.info("User logged in", email="john.doe@example.com", ip="192.168.1.100")
# # Output: User logged in email=[EMAIL-REDACTED] ip=[IP-REDACTED]
</code></pre>
<h4 id="structured-logging-sanitization"><a class="header" href="#structured-logging-sanitization">Structured Logging Sanitization</a></h4>
<pre><code class="language-python">def sanitize_for_logging(data: Dict[str, Any]) -&gt; Dict[str, Any]:
    """Sanitize data structure for logging."""
    SENSITIVE_KEYS = {
        "password", "api_key", "token", "secret", "authorization",
        "ssn", "credit_card", "phone", "email", "address",
        "passport", "drivers_license", "dob", "date_of_birth",
        "session_id", "cookie", "auth", "credential"
    }

    detector = CombinedPIIDetector()
    redactor = TypeBasedRedactor()

    def sanitize_value(key: str, value: Any) -&gt; Any:
        # Check if key is sensitive
        if any(sensitive in key.lower() for sensitive in SENSITIVE_KEYS):
            return "[REDACTED]"

        if isinstance(value, dict):
            return {k: sanitize_value(k, v) for k, v in value.items()}
        elif isinstance(value, list):
            return [sanitize_value(key, item) for item in value]
        elif isinstance(value, str):
            # Check if value contains PII
            findings = detector.detect(value)
            if findings:
                return redactor.redact(value, findings)

        return value

    return {k: sanitize_value(k, v) for k, v in data.items()}

# Example
# event_data = {
#     "user_id": "12345",
#     "email": "john.doe@example.com",
#     "action": "login",
#     "ip_address": "192.168.1.100",
#     "session_id": "abc123xyz",
#     "details": {
#         "user_agent": "Mozilla/5.0",
#         "phone": "555-123-4567"
#     }
# }
#
# sanitized = sanitize_for_logging(event_data)
# # Output:
# # {
# #     "user_id": "12345",
# #     "email": "[EMAIL-REDACTED]",
# #     "action": "login",
# #     "ip_address": "[IP-REDACTED]",
# #     "session_id": "[REDACTED]",
# #     "details": {
# #         "user_agent": "Mozilla/5.0",
# #         "phone": "[PHONE-REDACTED]"
# #     }
# # }
</code></pre>
<h3 id="sanitization-for-storage"><a class="header" href="#sanitization-for-storage">Sanitization for Storage</a></h3>
<p>Encrypt sensitive data before database storage:</p>
<pre><code class="language-python">from cryptography.fernet import Fernet
from typing import Dict, List
import asyncpg

class EncryptedDatabaseClient:
    """Database client with automatic field encryption."""

    def __init__(self, db_url: str, encryption_key: bytes = None):
        self.db_url = db_url

        # Initialize encryption
        if encryption_key is None:
            encryption_key = Fernet.generate_key()
        self.cipher = Fernet(encryption_key)

        # Define fields that should be encrypted
        self.encrypted_fields = {
            "users": ["email", "phone", "address"],
            "task_history": ["user_data"],
            "action_log": ["action_details"]
        }

        # Fields that should never be stored (always redacted)
        self.prohibited_fields = {
            "users": ["ssn", "credit_card", "password_plaintext"]
        }

    async def insert(self, table: str, data: Dict) -&gt; None:
        """Insert data with automatic encryption."""
        # Encrypt specified fields
        encrypted_data = self._encrypt_fields(table, data.copy())

        # Validate no prohibited fields
        self._validate_prohibited(table, encrypted_data)

        # Insert into database
        conn = await asyncpg.connect(self.db_url)
        try:
            columns = list(encrypted_data.keys())
            values = list(encrypted_data.values())
            placeholders = ','.join(f'${i+1}' for i in range(len(values)))

            query = f"INSERT INTO {table} ({','.join(columns)}) VALUES ({placeholders})"
            await conn.execute(query, *values)
        finally:
            await conn.close()

    async def select(self, table: str, conditions: Dict = None) -&gt; List[Dict]:
        """Select data with automatic decryption."""
        conn = await asyncpg.connect(self.db_url)
        try:
            query = f"SELECT * FROM {table}"
            if conditions:
                where_clause = ' AND '.join(f"{k} = ${i+1}" for i, k in enumerate(conditions.keys()))
                query += f" WHERE {where_clause}"
                rows = await conn.fetch(query, *conditions.values())
            else:
                rows = await conn.fetch(query)

            # Decrypt results
            results = []
            for row in rows:
                decrypted_row = self._decrypt_fields(table, dict(row))
                results.append(decrypted_row)

            return results
        finally:
            await conn.close()

    def _encrypt_fields(self, table: str, data: Dict) -&gt; Dict:
        """Encrypt sensitive fields."""
        if table not in self.encrypted_fields:
            return data

        for field in self.encrypted_fields[table]:
            if field in data and data[field] is not None:
                # Encrypt field value
                plaintext = str(data[field]).encode()
                encrypted = self.cipher.encrypt(plaintext)
                data[field] = encrypted.decode()

        return data

    def _decrypt_fields(self, table: str, data: Dict) -&gt; Dict:
        """Decrypt sensitive fields."""
        if table not in self.encrypted_fields:
            return data

        for field in self.encrypted_fields[table]:
            if field in data and data[field] is not None:
                # Decrypt field value
                try:
                    encrypted = data[field].encode()
                    decrypted = self.cipher.decrypt(encrypted)
                    data[field] = decrypted.decode()
                except Exception:
                    # Decryption failed (possibly not encrypted)
                    pass

        return data

    def _validate_prohibited(self, table: str, data: Dict):
        """Validate no prohibited fields are present."""
        if table not in self.prohibited_fields:
            return

        for field in self.prohibited_fields[table]:
            if field in data:
                raise ValueError(f"Prohibited field '{field}' cannot be stored in table '{table}'")

# Example
# db_client = EncryptedDatabaseClient(db_url="postgresql://...")
#
# # Insert with automatic encryption
# await db_client.insert("users", {
#     "user_id": "12345",
#     "email": "john.doe@example.com",  # Will be encrypted
#     "phone": "555-123-4567",           # Will be encrypted
#     "name": "John Doe"                 # Not encrypted
# })
#
# # Select with automatic decryption
# users = await db_client.select("users", {"user_id": "12345"})
# # Returns decrypted data
</code></pre>
<h3 id="sanitization-for-external-apis"><a class="header" href="#sanitization-for-external-apis">Sanitization for External APIs</a></h3>
<p>Sanitize data before external API calls:</p>
<pre><code class="language-python">import aiohttp
from typing import Dict, Any

class PIISanitizedAPIClient:
    """HTTP client with automatic PII sanitization."""

    def __init__(self, detector: CombinedPIIDetector, redactor):
        self.detector = detector
        self.redactor = redactor
        self.session = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.close()

    async def post(
        self,
        url: str,
        data: Dict[str, Any],
        sanitize: bool = True
    ) -&gt; Dict:
        """POST request with PII sanitization."""
        # Sanitize payload
        if sanitize:
            data = self._sanitize_payload(data)

        async with self.session.post(url, json=data) as response:
            response_data = await response.json()

            # Sanitize response
            if sanitize:
                response_data = self._sanitize_payload(response_data)

            return response_data

    async def get(
        self,
        url: str,
        params: Dict[str, str] = None,
        sanitize: bool = True
    ) -&gt; Dict:
        """GET request with PII sanitization."""
        # Sanitize query parameters
        if sanitize and params:
            params = self._sanitize_payload(params)

        async with self.session.get(url, params=params) as response:
            response_data = await response.json()

            # Sanitize response
            if sanitize:
                response_data = self._sanitize_payload(response_data)

            return response_data

    def _sanitize_payload(self, payload: Any) -&gt; Any:
        """Recursively sanitize payload."""
        if isinstance(payload, dict):
            return {
                k: self._sanitize_payload(v)
                for k, v in payload.items()
            }
        elif isinstance(payload, list):
            return [self._sanitize_payload(item) for item in payload]
        elif isinstance(payload, str):
            findings = self.detector.detect(payload)
            if findings:
                return self.redactor.redact(payload, findings)
            return payload
        else:
            return payload

# Example
# async with PIISanitizedAPIClient(
#     detector=CombinedPIIDetector(),
#     redactor=TypeBasedRedactor()
# ) as client:
#     # API call with automatic PII sanitization
#     response = await client.post(
#         "https://api.example.com/users",
#         data={
#             "name": "John Doe",
#             "email": "john.doe@example.com",
#             "message": "My SSN is 123-45-6789"
#         }
#     )
#     # Payload sent:
#     # {
#     #     "name": "John Doe",
#     #     "email": "[EMAIL-REDACTED]",
#     #     "message": "My SSN is [SSN-REDACTED]"
#     # }
</code></pre>
<h3 id="sanitization-testing"><a class="header" href="#sanitization-testing">Sanitization Testing</a></h3>
<p>Comprehensive test suite for sanitization:</p>
<pre><code class="language-python">import pytest
from typing import List

class SanitizationTestSuite:
    """Comprehensive sanitization testing."""

    def __init__(self, detector: CombinedPIIDetector, redactor):
        self.detector = detector
        self.redactor = redactor

    def test_basic_pii_types(self):
        """Test sanitization of all basic PII types."""
        test_cases = [
            ("Email: john.doe@example.com", "[EMAIL-REDACTED]"),
            ("SSN: 123-45-6789", "[SSN-REDACTED]"),
            ("Phone: 555-123-4567", "[PHONE-REDACTED]"),
            ("Credit Card: 4532-1234-5678-9010", "[CREDIT_CARD-REDACTED]"),
            ("IP: 192.168.1.100", "[IP_ADDRESS-REDACTED]"),
        ]

        for input_text, expected_redaction in test_cases:
            findings = self.detector.detect(input_text)
            redacted = self.redactor.redact(input_text, findings)
            assert expected_redaction in redacted, \
                f"Failed to redact: {input_text} -&gt; {redacted}"

    def test_multiple_pii_in_text(self):
        """Test sanitization of multiple PII instances."""
        text = "Contact John Doe at john.doe@example.com or call 555-123-4567. SSN: 123-45-6789"

        findings = self.detector.detect(text)
        assert len(findings) &gt;= 3, "Should detect at least email, phone, and SSN"

        redacted = self.redactor.redact(text, findings)

        # Verify no PII remains
        remaining_findings = self.detector.detect(redacted)
        assert len(remaining_findings) == 0, \
            f"PII still present in redacted text: {remaining_findings}"

    def test_edge_cases(self):
        """Test edge cases in sanitization."""
        edge_cases = [
            "",  # Empty string
            "No PII here",  # No PII
            "123-45-6789 123-45-6789",  # Duplicate PII
            "fake-555-1234",  # False positive
        ]

        for text in edge_cases:
            findings = self.detector.detect(text)
            redacted = self.redactor.redact(text, findings)
            # Should not crash
            assert isinstance(redacted, str)

    def test_structured_data_sanitization(self):
        """Test sanitization of nested data structures."""
        data = {
            "user": {
                "name": "John Doe",
                "email": "john.doe@example.com",
                "contacts": [
                    {"type": "phone", "value": "555-123-4567"},
                    {"type": "email", "value": "jane.doe@example.com"}
                ]
            },
            "metadata": {
                "ip": "192.168.1.100",
                "session": "abc123"
            }
        }

        sanitized = sanitize_for_logging(data)

        # Verify all emails redacted
        assert "[EMAIL-REDACTED]" in str(sanitized)
        assert "john.doe@example.com" not in str(sanitized)
        assert "jane.doe@example.com" not in str(sanitized)

    def test_performance(self):
        """Test sanitization performance."""
        import time

        # Generate test data
        test_texts = [
            f"User {i}: email{i}@example.com, phone {i:03d}-123-4567"
            for i in range(1000)
        ]

        start = time.time()
        for text in test_texts:
            findings = self.detector.detect(text)
            self.redactor.redact(text, findings)
        elapsed = time.time() - start

        throughput = len(test_texts) / elapsed
        assert throughput &gt; 100, \
            f"Performance too slow: {throughput:.2f} texts/sec (expected &gt;100)"

# Run tests
# suite = SanitizationTestSuite(
#     detector=CombinedPIIDetector(),
#     redactor=TypeBasedRedactor()
# )
# suite.test_basic_pii_types()
# suite.test_multiple_pii_in_text()
# suite.test_edge_cases()
# suite.test_structured_data_sanitization()
# suite.test_performance()
</code></pre>
<hr />
<h2 id="gdpr-compliance"><a class="header" href="#gdpr-compliance">GDPR Compliance</a></h2>
<h3 id="right-to-be-forgotten"><a class="header" href="#right-to-be-forgotten">Right to be Forgotten</a></h3>
<p>Implement GDPR Article 17 (Right to Erasure):</p>
<pre><code class="language-python">import asyncio
import asyncpg
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, FilterSelector
import redis.asyncio as redis
from typing import Dict, List
import structlog

logger = structlog.get_logger()

class RightToBeForgottenHandler:
    """Implements GDPR Right to be Forgotten."""

    def __init__(
        self,
        postgres_url: str,
        qdrant_url: str,
        redis_url: str
    ):
        self.postgres_url = postgres_url
        self.qdrant_client = QdrantClient(url=qdrant_url)
        self.redis_url = redis_url

    async def handle_erasure_request(
        self,
        user_id: str,
        request_source: str = "user",
        dry_run: bool = False
    ) -&gt; Dict:
        """Handle right to be forgotten request."""
        logger.info(
            "erasure_request_started",
            user_id=user_id,
            source=request_source,
            dry_run=dry_run
        )

        results = {
            "user_id": user_id,
            "dry_run": dry_run,
            "deleted": {},
            "anonymized": {},
            "errors": []
        }

        try:
            # Step 1: Delete from PostgreSQL
            postgres_result = await self._delete_from_postgres(user_id, dry_run)
            results["deleted"]["postgres"] = postgres_result

            # Step 2: Delete from Qdrant vector stores
            qdrant_result = await self._delete_from_qdrant(user_id, dry_run)
            results["deleted"]["qdrant"] = qdrant_result

            # Step 3: Delete from Redis cache
            redis_result = await self._delete_from_redis(user_id, dry_run)
            results["deleted"]["redis"] = redis_result

            # Step 4: Anonymize audit logs (keep for compliance but remove PII)
            audit_result = await self._anonymize_audit_logs(user_id, dry_run)
            results["anonymized"]["audit_logs"] = audit_result

            # Step 5: Log the deletion for compliance
            if not dry_run:
                await self._log_erasure_event(user_id, results)

            logger.info("erasure_request_completed", **results)

        except Exception as e:
            logger.error("erasure_request_failed", user_id=user_id, error=str(e))
            results["errors"].append(str(e))

        return results

    async def _delete_from_postgres(self, user_id: str, dry_run: bool) -&gt; Dict:
        """Delete user data from PostgreSQL."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            deleted_counts = {}

            # Tables to delete from
            tables = [
                "users",
                "task_history",
                "action_log",
                "user_preferences",
                "sessions"
            ]

            for table in tables:
                if dry_run:
                    # Count how many rows would be deleted
                    count = await conn.fetchval(
                        f"SELECT COUNT(*) FROM {table} WHERE user_id = $1",
                        user_id
                    )
                else:
                    # Actually delete
                    result = await conn.execute(
                        f"DELETE FROM {table} WHERE user_id = $1",
                        user_id
                    )
                    # Parse result like "DELETE 5"
                    count = int(result.split()[-1])

                deleted_counts[table] = count

            return deleted_counts

        finally:
            await conn.close()

    async def _delete_from_qdrant(self, user_id: str, dry_run: bool) -&gt; Dict:
        """Delete user vectors from Qdrant collections."""
        deleted_counts = {}

        # Get all collections
        collections = self.qdrant_client.get_collections().collections

        for collection in collections:
            collection_name = collection.name

            if dry_run:
                # Count points that would be deleted
                result = self.qdrant_client.scroll(
                    collection_name=collection_name,
                    scroll_filter=Filter(
                        must=[
                            FieldCondition(
                                key="user_id",
                                match=MatchValue(value=user_id)
                            )
                        ]
                    ),
                    limit=1000
                )
                count = len(result[0])
            else:
                # Delete points
                self.qdrant_client.delete(
                    collection_name=collection_name,
                    points_selector=FilterSelector(
                        filter=Filter(
                            must=[
                                FieldCondition(
                                    key="user_id",
                                    match=MatchValue(value=user_id)
                                )
                            ]
                        )
                    )
                )
                count = "deleted"  # Qdrant doesn't return count

            deleted_counts[collection_name] = count

        return deleted_counts

    async def _delete_from_redis(self, user_id: str, dry_run: bool) -&gt; Dict:
        """Delete user data from Redis cache."""
        client = await redis.from_url(self.redis_url)
        try:
            # Find all keys for user
            pattern = f"user:{user_id}:*"
            keys = []

            async for key in client.scan_iter(match=pattern):
                keys.append(key)

            if not dry_run and keys:
                # Delete all keys
                await client.delete(*keys)

            return {
                "pattern": pattern,
                "keys_found": len(keys),
                "deleted": len(keys) if not dry_run else 0
            }

        finally:
            await client.close()

    async def _anonymize_audit_logs(self, user_id: str, dry_run: bool) -&gt; Dict:
        """Anonymize audit logs while preserving compliance records."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            # Count audit logs
            count = await conn.fetchval(
                "SELECT COUNT(*) FROM audit_logs WHERE user_id = $1",
                user_id
            )

            if not dry_run:
                # Update user_id to anonymized value
                anonymized_id = f"ANONYMIZED_{hash(user_id) % 1000000:06d}"

                await conn.execute(
                    """
                    UPDATE audit_logs
                    SET user_id = $1,
                        user_data = 'ANONYMIZED',
                        anonymized_at = NOW()
                    WHERE user_id = $2
                    """,
                    anonymized_id,
                    user_id
                )

            return {
                "audit_logs_anonymized": count,
                "retention_period": "1 year (compliance requirement)"
            }

        finally:
            await conn.close()

    async def _log_erasure_event(self, user_id: str, results: Dict):
        """Log erasure event for compliance."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            await conn.execute(
                """
                INSERT INTO data_erasure_log (
                    user_id,
                    request_date,
                    completion_date,
                    results
                ) VALUES ($1, NOW(), NOW(), $2)
                """,
                user_id,
                json.dumps(results)
            )
        finally:
            await conn.close()

# Example usage
# handler = RightToBeForgottenHandler(
#     postgres_url="postgresql://...",
#     qdrant_url="http://localhost:6333",
#     redis_url="redis://localhost:6379"
# )
#
# # Dry run first
# dry_run_results = await handler.handle_erasure_request(
#     user_id="user_12345",
#     dry_run=True
# )
# print(f"Would delete: {dry_run_results}")
#
# # Actual deletion
# results = await handler.handle_erasure_request(
#     user_id="user_12345",
#     dry_run=False
# )
# print(f"Deleted: {results}")
</code></pre>
<h3 id="data-portability"><a class="header" href="#data-portability">Data Portability</a></h3>
<p>Implement GDPR Article 20 (Right to Data Portability):</p>
<pre><code class="language-python">import json
import csv
import io
from datetime import datetime
from typing import Dict, List, Any

class DataPortabilityHandler:
    """Implements GDPR Right to Data Portability."""

    def __init__(self, postgres_url: str, qdrant_url: str):
        self.postgres_url = postgres_url
        self.qdrant_client = QdrantClient(url=qdrant_url)

    async def export_user_data(
        self,
        user_id: str,
        format: str = "json"  # json, csv, xml
    ) -&gt; bytes:
        """Export all user data in machine-readable format."""
        logger.info("data_export_started", user_id=user_id, format=format)

        # Collect data from all sources
        data = {
            "export_metadata": {
                "user_id": user_id,
                "export_date": datetime.utcnow().isoformat(),
                "format": format,
                "version": "1.0"
            },
            "user_profile": await self._export_user_profile(user_id),
            "task_history": await self._export_task_history(user_id),
            "preferences": await self._export_preferences(user_id),
            "audit_logs": await self._export_audit_logs(user_id),
            "vector_memories": await self._export_vector_memories(user_id)
        }

        # Convert to requested format
        if format == "json":
            output = json.dumps(data, indent=2, default=str)
            return output.encode()
        elif format == "csv":
            return self._export_as_csv(data)
        elif format == "xml":
            return self._export_as_xml(data)
        else:
            raise ValueError(f"Unsupported format: {format}")

    async def _export_user_profile(self, user_id: str) -&gt; Dict:
        """Export user profile data."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            profile = await conn.fetchrow(
                "SELECT * FROM users WHERE id = $1",
                user_id
            )
            return dict(profile) if profile else {}
        finally:
            await conn.close()

    async def _export_task_history(self, user_id: str) -&gt; List[Dict]:
        """Export task execution history."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            tasks = await conn.fetch(
                """
                SELECT * FROM task_history
                WHERE user_id = $1
                ORDER BY created_at DESC
                """,
                user_id
            )
            return [dict(task) for task in tasks]
        finally:
            await conn.close()

    async def _export_preferences(self, user_id: str) -&gt; Dict:
        """Export user preferences."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            prefs = await conn.fetch(
                "SELECT * FROM user_preferences WHERE user_id = $1",
                user_id
            )
            return {pref["key"]: pref["value"] for pref in prefs}
        finally:
            await conn.close()

    async def _export_audit_logs(self, user_id: str) -&gt; List[Dict]:
        """Export audit logs (last 90 days)."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            logs = await conn.fetch(
                """
                SELECT * FROM audit_logs
                WHERE user_id = $1
                  AND created_at &gt; NOW() - INTERVAL '90 days'
                ORDER BY created_at DESC
                """,
                user_id
            )
            return [dict(log) for log in logs]
        finally:
            await conn.close()

    async def _export_vector_memories(self, user_id: str) -&gt; Dict:
        """Export vector embeddings and associated data."""
        memories = {}

        collections = self.qdrant_client.get_collections().collections

        for collection in collections:
            collection_name = collection.name

            # Scroll through user's points
            result = self.qdrant_client.scroll(
                collection_name=collection_name,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(
                            key="user_id",
                            match=MatchValue(value=user_id)
                        )
                    ]
                ),
                limit=1000,
                with_payload=True,
                with_vectors=False  # Don't export raw vectors (too large)
            )

            points, _ = result

            if points:
                memories[collection_name] = [
                    {
                        "id": str(point.id),
                        "payload": point.payload
                    }
                    for point in points
                ]

        return memories

    def _export_as_csv(self, data: Dict) -&gt; bytes:
        """Export data as CSV (flattened structure)."""
        output = io.StringIO()

        # Export each section as separate CSV
        csv_output = ""

        for section, section_data in data.items():
            if section == "export_metadata":
                continue

            csv_output += f"\n# {section.upper()}\n"

            if isinstance(section_data, list) and section_data:
                # Table data
                writer = csv.DictWriter(
                    output,
                    fieldnames=section_data[0].keys()
                )
                writer.writeheader()
                writer.writerows(section_data)
                csv_output += output.getvalue()
                output = io.StringIO()  # Reset
            elif isinstance(section_data, dict):
                # Key-value data
                writer = csv.writer(output)
                writer.writerow(["Key", "Value"])
                for key, value in section_data.items():
                    writer.writerow([key, str(value)])
                csv_output += output.getvalue()
                output = io.StringIO()  # Reset

        return csv_output.encode()

    def _export_as_xml(self, data: Dict) -&gt; bytes:
        """Export data as XML."""
        import xml.etree.ElementTree as ET

        root = ET.Element("user_data_export")

        def dict_to_xml(parent, data):
            if isinstance(data, dict):
                for key, value in data.items():
                    child = ET.SubElement(parent, str(key))
                    dict_to_xml(child, value)
            elif isinstance(data, list):
                for item in data:
                    item_elem = ET.SubElement(parent, "item")
                    dict_to_xml(item_elem, item)
            else:
                parent.text = str(data)

        dict_to_xml(root, data)

        tree = ET.ElementTree(root)
        output = io.BytesIO()
        tree.write(output, encoding="utf-8", xml_declaration=True)

        return output.getvalue()

# Example usage
# handler = DataPortabilityHandler(
#     postgres_url="postgresql://...",
#     qdrant_url="http://localhost:6333"
# )
#
# # Export as JSON
# json_export = await handler.export_user_data(
#     user_id="user_12345",
#     format="json"
# )
#
# # Save to file
# with open(f"user_12345_export.json", "wb") as f:
#     f.write(json_export)
</code></pre>
<h3 id="consent-management"><a class="header" href="#consent-management">Consent Management</a></h3>
<p>Track and enforce user consent:</p>
<pre><code class="language-python">from enum import Enum
from datetime import datetime, timedelta
from typing import Optional, List

class ConsentType(str, Enum):
    NECESSARY = "necessary"           # Required for service operation
    FUNCTIONAL = "functional"         # Enhances functionality
    ANALYTICS = "analytics"           # Usage analytics
    MARKETING = "marketing"           # Marketing communications
    THIRD_PARTY_SHARING = "third_party_sharing"  # Share with partners

class ConsentStatus(str, Enum):
    GRANTED = "granted"
    DENIED = "denied"
    WITHDRAWN = "withdrawn"
    EXPIRED = "expired"

@dataclass
class ConsentRecord:
    """User consent record."""
    user_id: str
    consent_type: ConsentType
    status: ConsentStatus
    granted_at: Optional[datetime] = None
    withdrawn_at: Optional[datetime] = None
    expires_at: Optional[datetime] = None
    version: str = "1.0"
    method: str = "explicit"  # explicit, implied
    ip_address: Optional[str] = None

class ConsentManager:
    """Manage user consent records."""

    def __init__(self, postgres_url: str):
        self.postgres_url = postgres_url

    async def grant_consent(
        self,
        user_id: str,
        consent_type: ConsentType,
        ip_address: Optional[str] = None,
        duration_days: Optional[int] = None
    ) -&gt; ConsentRecord:
        """Grant consent for a specific purpose."""
        now = datetime.utcnow()
        expires_at = None

        if duration_days:
            expires_at = now + timedelta(days=duration_days)

        record = ConsentRecord(
            user_id=user_id,
            consent_type=consent_type,
            status=ConsentStatus.GRANTED,
            granted_at=now,
            expires_at=expires_at,
            ip_address=ip_address
        )

        # Store in database
        await self._store_consent(record)

        logger.info(
            "consent_granted",
            user_id=user_id,
            type=consent_type.value,
            expires_at=expires_at
        )

        return record

    async def withdraw_consent(
        self,
        user_id: str,
        consent_type: ConsentType
    ) -&gt; ConsentRecord:
        """Withdraw previously granted consent."""
        # Get existing consent
        existing = await self._get_consent(user_id, consent_type)

        if not existing:
            raise ValueError(f"No consent found for {consent_type}")

        # Update status
        existing.status = ConsentStatus.WITHDRAWN
        existing.withdrawn_at = datetime.utcnow()

        await self._store_consent(existing)

        logger.info(
            "consent_withdrawn",
            user_id=user_id,
            type=consent_type.value
        )

        return existing

    async def check_consent(
        self,
        user_id: str,
        consent_type: ConsentType
    ) -&gt; bool:
        """Check if user has granted consent."""
        record = await self._get_consent(user_id, consent_type)

        if not record:
            # Necessary consent is always granted
            if consent_type == ConsentType.NECESSARY:
                return True
            return False

        # Check if withdrawn
        if record.status == ConsentStatus.WITHDRAWN:
            return False

        # Check if expired
        if record.expires_at and record.expires_at &lt; datetime.utcnow():
            # Update status
            record.status = ConsentStatus.EXPIRED
            await self._store_consent(record)
            return False

        return record.status == ConsentStatus.GRANTED

    async def get_all_consents(self, user_id: str) -&gt; List[ConsentRecord]:
        """Get all consent records for user."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            rows = await conn.fetch(
                "SELECT * FROM user_consents WHERE user_id = $1",
                user_id
            )

            return [
                ConsentRecord(
                    user_id=row["user_id"],
                    consent_type=ConsentType(row["consent_type"]),
                    status=ConsentStatus(row["status"]),
                    granted_at=row["granted_at"],
                    withdrawn_at=row["withdrawn_at"],
                    expires_at=row["expires_at"],
                    version=row["version"],
                    method=row["method"],
                    ip_address=row["ip_address"]
                )
                for row in rows
            ]
        finally:
            await conn.close()

    async def _store_consent(self, record: ConsentRecord):
        """Store consent record in database."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            await conn.execute(
                """
                INSERT INTO user_consents (
                    user_id, consent_type, status, granted_at,
                    withdrawn_at, expires_at, version, method, ip_address
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                ON CONFLICT (user_id, consent_type)
                DO UPDATE SET
                    status = EXCLUDED.status,
                    withdrawn_at = EXCLUDED.withdrawn_at,
                    updated_at = NOW()
                """,
                record.user_id,
                record.consent_type.value,
                record.status.value,
                record.granted_at,
                record.withdrawn_at,
                record.expires_at,
                record.version,
                record.method,
                record.ip_address
            )
        finally:
            await conn.close()

    async def _get_consent(
        self,
        user_id: str,
        consent_type: ConsentType
    ) -&gt; Optional[ConsentRecord]:
        """Get consent record from database."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            row = await conn.fetchrow(
                """
                SELECT * FROM user_consents
                WHERE user_id = $1 AND consent_type = $2
                """,
                user_id,
                consent_type.value
            )

            if not row:
                return None

            return ConsentRecord(
                user_id=row["user_id"],
                consent_type=ConsentType(row["consent_type"]),
                status=ConsentStatus(row["status"]),
                granted_at=row["granted_at"],
                withdrawn_at=row["withdrawn_at"],
                expires_at=row["expires_at"],
                version=row["version"],
                method=row["method"],
                ip_address=row["ip_address"]
            )
        finally:
            await conn.close()

# Example usage
# consent_mgr = ConsentManager(postgres_url="postgresql://...")
#
# # Grant consent
# await consent_mgr.grant_consent(
#     user_id="user_12345",
#     consent_type=ConsentType.ANALYTICS,
#     ip_address="192.168.1.100",
#     duration_days=365
# )
#
# # Check consent before analytics
# if await consent_mgr.check_consent("user_12345", ConsentType.ANALYTICS):
#     # Collect analytics
#     pass
#
# # Withdraw consent
# await consent_mgr.withdraw_consent(
#     user_id="user_12345",
#     consent_type=ConsentType.ANALYTICS
# )
</code></pre>
<h3 id="privacy-impact-assessments"><a class="header" href="#privacy-impact-assessments">Privacy Impact Assessments</a></h3>
<p>Conduct DPIAs for high-risk processing:</p>
<pre><code class="language-python">from enum import Enum
from typing import List, Dict
from dataclasses import dataclass, field

class RiskLevel(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    VERY_HIGH = "very_high"

class ProcessingPurpose(str, Enum):
    TASK_EXECUTION = "task_execution"
    USER_ANALYTICS = "user_analytics"
    SECURITY_MONITORING = "security_monitoring"
    MODEL_TRAINING = "model_training"
    SYSTEM_OPTIMIZATION = "system_optimization"

@dataclass
class DPIAAssessment:
    """Data Protection Impact Assessment."""
    assessment_id: str
    title: str
    description: str
    processing_purpose: ProcessingPurpose
    data_categories: List[str] = field(default_factory=list)
    data_subjects: List[str] = field(default_factory=list)

    # Risk assessment
    necessity_and_proportionality: str = ""
    risks_identified: List[Dict] = field(default_factory=list)
    overall_risk_level: RiskLevel = RiskLevel.MEDIUM

    # Mitigation measures
    mitigations: List[str] = field(default_factory=list)
    residual_risk: RiskLevel = RiskLevel.LOW

    # Compliance
    lawful_basis: str = ""
    data_minimization_applied: bool = False
    encryption_in_transit: bool = False
    encryption_at_rest: bool = False
    access_controls: List[str] = field(default_factory=list)
    retention_period: str = ""

    # Approval
    approved_by: str = ""
    approval_date: Optional[datetime] = None
    review_date: Optional[datetime] = None

class DPIATemplate:
    """Template for conducting DPIAs."""

    @staticmethod
    def create_task_execution_dpia() -&gt; DPIAAssessment:
        """DPIA for task execution processing."""
        return DPIAAssessment(
            assessment_id="DPIA-001",
            title="Task Execution Processing",
            description="Processing of user tasks including potential PII in inputs/outputs",
            processing_purpose=ProcessingPurpose.TASK_EXECUTION,
            data_categories=[
                "Task descriptions",
                "User inputs (may contain PII)",
                "Task results",
                "Execution metadata"
            ],
            data_subjects=[
                "OctoLLM users",
                "Third parties mentioned in tasks"
            ],
            necessity_and_proportionality="""
            Processing is necessary for service delivery.
            PII is minimized through automatic detection and redaction.
            Only necessary data is collected and retained.
            """,
            risks_identified=[
                {
                    "risk": "Unintended PII collection in user inputs",
                    "likelihood": "high",
                    "impact": "medium",
                    "risk_level": RiskLevel.HIGH
                },
                {
                    "risk": "PII leakage in task results",
                    "likelihood": "medium",
                    "impact": "high",
                    "risk_level": RiskLevel.HIGH
                },
                {
                    "risk": "Unauthorized access to task history",
                    "likelihood": "low",
                    "impact": "high",
                    "risk_level": RiskLevel.MEDIUM
                }
            ],
            overall_risk_level=RiskLevel.HIGH,
            mitigations=[
                "Automatic PII detection in all inputs (Guardian Arm)",
                "PII redaction before storage",
                "Encryption of task history at rest (AES-256)",
                "Access controls (RBAC) on task data",
                "90-day retention with automatic deletion",
                "Audit logging of all access"
            ],
            residual_risk=RiskLevel.LOW,
            lawful_basis="Legitimate interest (service delivery)",
            data_minimization_applied=True,
            encryption_in_transit=True,
            encryption_at_rest=True,
            access_controls=[
                "User authentication required",
                "RBAC enforced",
                "Capability-based access control",
                "Audit logging"
            ],
            retention_period="90 days (anonymized after 30 days)"
        )

    @staticmethod
    def create_model_training_dpia() -&gt; DPIAAssessment:
        """DPIA for model training on user data."""
        return DPIAAssessment(
            assessment_id="DPIA-002",
            title="Model Training on Task Data",
            description="Fine-tuning specialist models on anonymized task execution traces",
            processing_purpose=ProcessingPurpose.MODEL_TRAINING,
            data_categories=[
                "Task execution traces (anonymized)",
                "Success/failure outcomes",
                "Performance metrics"
            ],
            data_subjects=[
                "OctoLLM users (anonymized)"
            ],
            necessity_and_proportionality="""
            Processing improves system performance and reduces costs.
            All PII removed before training.
            Users can opt-out.
            """,
            risks_identified=[
                {
                    "risk": "Re-identification from anonymized data",
                    "likelihood": "low",
                    "impact": "high",
                    "risk_level": RiskLevel.MEDIUM
                },
                {
                    "risk": "Model memorization of sensitive patterns",
                    "likelihood": "medium",
                    "impact": "medium",
                    "risk_level": RiskLevel.MEDIUM
                }
            ],
            overall_risk_level=RiskLevel.MEDIUM,
            mitigations=[
                "Differential privacy (epsilon=1.0)",
                "PII removal before training",
                "K-anonymity (k=10) for training data",
                "User opt-out mechanism",
                "Regular model audits for memorization"
            ],
            residual_risk=RiskLevel.LOW,
            lawful_basis="Legitimate interest + user consent",
            data_minimization_applied=True,
            encryption_in_transit=True,
            encryption_at_rest=True,
            access_controls=[
                "ML team only",
                "Training data access logged",
                "Secure training environment"
            ],
            retention_period="Training data: 180 days, Models: indefinite"
        )

# Generate DPIA report
# dpia = DPIATemplate.create_task_execution_dpia()
#
# # Generate compliance report
# report = f"""
# Data Protection Impact Assessment
# ==================================
#
# Assessment ID: {dpia.assessment_id}
# Title: {dpia.title}
#
# Processing Purpose: {dpia.processing_purpose.value}
#
# Risk Assessment
# ---------------
# Overall Risk Level: {dpia.overall_risk_level.value}
# Residual Risk: {dpia.residual_risk.value}
#
# Risks Identified:
# {chr(10).join(f"- {r['risk']} (Likelihood: {r['likelihood']}, Impact: {r['impact']})" for r in dpia.risks_identified)}
#
# Mitigations:
# {chr(10).join(f"- {m}" for m in dpia.mitigations)}
#
# Compliance Measures:
# - Data minimization: {dpia.data_minimization_applied}
# - Encryption in transit: {dpia.encryption_in_transit}
# - Encryption at rest: {dpia.encryption_at_rest}
# - Retention period: {dpia.retention_period}
# """
</code></pre>
<h3 id="data-minimization"><a class="header" href="#data-minimization">Data Minimization</a></h3>
<p>Implement data minimization principles:</p>
<pre><code class="language-python">class DataMinimizationPolicy:
    """Enforce data minimization principles."""

    @staticmethod
    def minimize_task_storage(task_data: Dict) -&gt; Dict:
        """Remove unnecessary data before storage."""
        # Keep only essential fields
        minimized = {
            "task_id": task_data.get("task_id"),
            "goal_hash": hashlib.sha256(
                task_data.get("goal", "").encode()
            ).hexdigest()[:16],  # Hash instead of full goal
            "success": task_data.get("success"),
            "duration_ms": task_data.get("duration_ms"),
            "cost_tokens": task_data.get("cost_tokens"),
            "created_at": task_data.get("created_at")
        }

        # Don't store:
        # - Full goal text (use hash)
        # - Detailed results (only success/failure)
        # - User inputs (may contain PII)
        # - Internal execution details

        return minimized

    @staticmethod
    def anonymize_after_retention(task_data: Dict, days: int = 30) -&gt; Dict:
        """Anonymize old task data."""
        created_at = task_data.get("created_at")

        if created_at and (datetime.utcnow() - created_at).days &gt; days:
            # Anonymize user-identifiable data
            task_data["user_id"] = f"ANON_{hash(task_data['user_id']) % 1000000:06d}"
            task_data["goal"] = "[ANONYMIZED]"
            task_data["results"] = {"status": task_data.get("success")}

        return task_data

    @staticmethod
    def aggregate_instead_of_raw(raw_data: List[Dict]) -&gt; Dict:
        """Store aggregated metrics instead of raw data."""
        # Instead of storing individual task executions
        # Store aggregated statistics

        aggregated = {
            "total_tasks": len(raw_data),
            "success_rate": sum(1 for t in raw_data if t.get("success")) / len(raw_data) if raw_data else 0,
            "avg_duration_ms": sum(t.get("duration_ms", 0) for t in raw_data) / len(raw_data) if raw_data else 0,
            "total_tokens": sum(t.get("cost_tokens", 0) for t in raw_data),
            "period_start": min(t.get("created_at") for t in raw_data) if raw_data else None,
            "period_end": max(t.get("created_at") for t in raw_data) if raw_data else None
        }

        return aggregated

# Automated data minimization job
# async def run_data_minimization():
#     """Periodic job to minimize stored data."""
#     conn = await asyncpg.connect(postgres_url)
#
#     try:
#         # Anonymize tasks older than 30 days
#         await conn.execute(
#             """
#             UPDATE task_history
#             SET user_id = 'ANON_' || (hashtext(user_id)::text),
#                 goal = '[ANONYMIZED]',
#                 results = jsonb_build_object('status', success)
#             WHERE created_at &lt; NOW() - INTERVAL '30 days'
#               AND user_id NOT LIKE 'ANON_%'
#             """
#         )
#
#         # Delete tasks older than 90 days
#         await conn.execute(
#             """
#             DELETE FROM task_history
#             WHERE created_at &lt; NOW() - INTERVAL '90 days'
#             """
#         )
#
#     finally:
#         await conn.close()
</code></pre>
<hr />
<h2 id="ccpa-compliance"><a class="header" href="#ccpa-compliance">CCPA Compliance</a></h2>
<h3 id="consumer-rights"><a class="header" href="#consumer-rights">Consumer Rights</a></h3>
<p>Implement CCPA consumer rights:</p>
<pre><code class="language-python">class CCPAConsumerRights:
    """Implements CCPA consumer rights."""

    def __init__(self, postgres_url: str):
        self.postgres_url = postgres_url

    async def right_to_know(self, user_id: str) -&gt; Dict:
        """Implement right to know what data is collected."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            # Categories of personal information collected
            categories = {
                "identifiers": [],
                "commercial_information": [],
                "internet_activity": [],
                "inferences": []
            }

            # Get user data
            user = await conn.fetchrow(
                "SELECT * FROM users WHERE id = $1",
                user_id
            )

            if user:
                if user.get("email"):
                    categories["identifiers"].append("Email address")
                if user.get("phone"):
                    categories["identifiers"].append("Phone number")
                if user.get("ip_address"):
                    categories["identifiers"].append("IP address")

            # Get task history
            task_count = await conn.fetchval(
                "SELECT COUNT(*) FROM task_history WHERE user_id = $1",
                user_id
            )
            if task_count &gt; 0:
                categories["commercial_information"].append(
                    f"Task execution history ({task_count} tasks)"
                )
                categories["internet_activity"].append(
                    "System interaction logs"
                )

            # Get inferences
            categories["inferences"].append(
                "Usage patterns and preferences"
            )

            return {
                "user_id": user_id,
                "categories_of_data": categories,
                "sources": [
                    "Directly from user",
                    "From user's device/browser",
                    "From user's interaction with service"
                ],
                "business_purposes": [
                    "Providing and improving service",
                    "Security and fraud prevention",
                    "System optimization"
                ],
                "third_parties_shared_with": [
                    "None (data not sold or shared)"
                ]
            }
        finally:
            await conn.close()

    async def right_to_delete(self, user_id: str) -&gt; Dict:
        """Implement right to delete (similar to GDPR erasure)."""
        # Reuse GDPR right to be forgotten handler
        handler = RightToBeForgottenHandler(
            postgres_url=self.postgres_url,
            qdrant_url="http://qdrant:6333",
            redis_url="redis://redis:6379"
        )

        return await handler.handle_erasure_request(user_id)

    async def right_to_opt_out(
        self,
        user_id: str,
        opt_out_type: str  # "sale", "sharing", "targeted_advertising"
    ) -&gt; bool:
        """Implement right to opt out of sale/sharing."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            await conn.execute(
                """
                INSERT INTO ccpa_opt_outs (user_id, opt_out_type, opted_out_at)
                VALUES ($1, $2, NOW())
                ON CONFLICT (user_id, opt_out_type)
                DO UPDATE SET opted_out_at = NOW(), withdrawn_at = NULL
                """,
                user_id,
                opt_out_type
            )

            logger.info(
                "ccpa_opt_out_recorded",
                user_id=user_id,
                type=opt_out_type
            )

            return True
        finally:
            await conn.close()

    async def check_opt_out_status(
        self,
        user_id: str,
        opt_out_type: str
    ) -&gt; bool:
        """Check if user has opted out."""
        conn = await asyncpg.connect(self.postgres_url)
        try:
            row = await conn.fetchrow(
                """
                SELECT * FROM ccpa_opt_outs
                WHERE user_id = $1 AND opt_out_type = $2
                  AND withdrawn_at IS NULL
                """,
                user_id,
                opt_out_type
            )

            return row is not None
        finally:
            await conn.close()
</code></pre>
<h3 id="opt-out-mechanisms"><a class="header" href="#opt-out-mechanisms">Opt-Out Mechanisms</a></h3>
<p>Global Privacy Control (GPC) support:</p>
<pre><code class="language-python">from fastapi import FastAPI, Request, Response
from typing import Dict

app = FastAPI()

class GPCHandler:
    """Handle Global Privacy Control signals."""

    @staticmethod
    def detect_gpc_signal(request: Request) -&gt; bool:
        """Detect GPC signal in request headers."""
        # Check Sec-GPC header
        gpc_header = request.headers.get("Sec-GPC")

        if gpc_header == "1":
            return True

        return False

    @staticmethod
    async def apply_gpc_preferences(user_id: str):
        """Apply GPC-based opt-out preferences."""
        ccpa_rights = CCPAConsumerRights(postgres_url="postgresql://...")

        # Opt out of all CCPA-covered activities
        await ccpa_rights.right_to_opt_out(user_id, "sale")
        await ccpa_rights.right_to_opt_out(user_id, "sharing")
        await ccpa_rights.right_to_opt_out(user_id, "targeted_advertising")

@app.middleware("http")
async def gpc_middleware(request: Request, call_next):
    """Middleware to detect and honor GPC signals."""
    if GPCHandler.detect_gpc_signal(request):
        # Extract user_id from session/auth
        user_id = request.state.user_id if hasattr(request.state, "user_id") else None

        if user_id:
            # Apply GPC preferences
            await GPCHandler.apply_gpc_preferences(user_id)

            logger.info("gpc_signal_honored", user_id=user_id)

    response = await call_next(request)
    return response
</code></pre>
<h3 id="privacy-notices"><a class="header" href="#privacy-notices">Privacy Notices</a></h3>
<p>Implement CCPA notice requirements:</p>
<pre><code class="language-python">class CCPANoticeGenerator:
    """Generate CCPA-compliant privacy notices."""

    @staticmethod
    def notice_at_collection() -&gt; str:
        """Generate notice at collection."""
        return """
        NOTICE AT COLLECTION OF PERSONAL INFORMATION

        We collect the following categories of personal information:

        1. Identifiers
           - Email address, IP address
           - Purpose: Account creation, service delivery

        2. Commercial Information
           - Task execution history, usage patterns
           - Purpose: Service delivery, improvement

        3. Internet Activity
           - System interaction logs, performance metrics
           - Purpose: System optimization, security

        4. Inferences
           - Usage preferences, behavior patterns
           - Purpose: Service personalization

        You have the right to:
        - Know what personal information is collected
        - Request deletion of personal information
        - Opt-out of sale/sharing (we do not sell or share)
        - Non-discrimination for exercising your rights

        To exercise your rights, contact privacy@octollm.example.com
        """

    @staticmethod
    def privacy_policy() -&gt; Dict:
        """Generate comprehensive privacy policy."""
        return {
            "effective_date": "2025-01-01",
            "last_updated": "2025-11-10",
            "sections": [
                {
                    "title": "Information We Collect",
                    "content": """
                    We collect information you provide directly, automatically
                    from your device, and from third-party sources.
                    """
                },
                {
                    "title": "How We Use Your Information",
                    "content": """
                    We use collected information to provide services, improve
                    system performance, ensure security, and communicate with you.
                    """
                },
                {
                    "title": "Information Sharing",
                    "content": """
                    We do not sell personal information. We do not share personal
                    information except as necessary for service delivery.
                    """
                },
                {
                    "title": "Your Rights",
                    "content": """
                    You have rights under GDPR, CCPA, and other privacy laws
                    including rights to access, delete, and control your data.
                    """
                },
                {
                    "title": "Data Security",
                    "content": """
                    We implement industry-standard security measures including
                    encryption, access controls, and regular security audits.
                    """
                },
                {
                    "title": "Contact Information",
                    "content": """
                    For privacy-related questions: privacy@octollm.example.com
                    """
                }
            ]
        }

# Example API endpoint
# @app.get("/api/privacy/notice")
# async def get_privacy_notice():
#     """Return privacy notice at collection."""
#     return {
#         "notice": CCPANoticeGenerator.notice_at_collection()
#     }
#
# @app.get("/api/privacy/policy")
# async def get_privacy_policy():
#     """Return full privacy policy."""
#     return CCPANoticeGenerator.privacy_policy()
</code></pre>
<h3 id="data-sale-disclosure"><a class="header" href="#data-sale-disclosure">Data Sale Disclosure</a></h3>
<p>Implement "Do Not Sell My Personal Information" link:</p>
<pre><code class="language-python">@app.get("/do-not-sell")
async def do_not_sell_page():
    """Render 'Do Not Sell My Personal Information' page."""
    return """
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;Do Not Sell My Personal Information&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h1&gt;Do Not Sell My Personal Information&lt;/h1&gt;

        &lt;p&gt;&lt;strong&gt;OctoLLM does not sell personal information.&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;As a matter of policy, we do not sell or share personal information
        with third parties for their own marketing purposes.&lt;/p&gt;

        &lt;p&gt;However, if you would like to formally opt-out of any potential
        future data sales or sharing, you can do so below:&lt;/p&gt;

        &lt;form method="POST" action="/api/ccpa/opt-out"&gt;
            &lt;label&gt;
                &lt;input type="checkbox" name="opt_out_sale" checked disabled&gt;
                Opt-out of sale of personal information
            &lt;/label&gt;
            &lt;br&gt;
            &lt;label&gt;
                &lt;input type="checkbox" name="opt_out_sharing" checked disabled&gt;
                Opt-out of sharing of personal information
            &lt;/label&gt;
            &lt;br&gt;
            &lt;label&gt;
                &lt;input type="checkbox" name="opt_out_targeted_ads" checked disabled&gt;
                Opt-out of targeted advertising
            &lt;/label&gt;
            &lt;br&gt;&lt;br&gt;
            &lt;button type="submit"&gt;Submit Opt-Out Request&lt;/button&gt;
        &lt;/form&gt;

        &lt;p&gt;For questions, contact: privacy@octollm.example.com&lt;/p&gt;
    &lt;/body&gt;
    &lt;/html&gt;
    """

@app.post("/api/ccpa/opt-out")
async def handle_opt_out(request: Request):
    """Handle opt-out form submission."""
    user_id = request.state.user_id  # From auth middleware

    ccpa_rights = CCPAConsumerRights(postgres_url="postgresql://...")

    # Record all opt-outs
    await ccpa_rights.right_to_opt_out(user_id, "sale")
    await ccpa_rights.right_to_opt_out(user_id, "sharing")
    await ccpa_rights.right_to_opt_out(user_id, "targeted_advertising")

    return {
        "status": "success",
        "message": "Your opt-out preferences have been recorded."
    }
</code></pre>
<hr />
<h2 id="differential-privacy"><a class="header" href="#differential-privacy">Differential Privacy</a></h2>
<h3 id="noise-addition"><a class="header" href="#noise-addition">Noise Addition</a></h3>
<p>Implement differential privacy with noise addition:</p>
<pre><code class="language-python">import numpy as np
from typing import Union, List

class DifferentialPrivacy:
    """Differential privacy mechanisms."""

    @staticmethod
    def add_laplace_noise(
        value: float,
        epsilon: float = 1.0,
        sensitivity: float = 1.0
    ) -&gt; float:
        """Add Laplace noise for epsilon-differential privacy."""
        # Scale parameter for Laplace distribution
        scale = sensitivity / epsilon

        # Generate Laplace noise
        noise = np.random.laplace(0, scale)

        return value + noise

    @staticmethod
    def add_gaussian_noise(
        value: float,
        epsilon: float = 1.0,
        delta: float = 1e-5,
        sensitivity: float = 1.0
    ) -&gt; float:
        """Add Gaussian noise for (epsilon, delta)-differential privacy."""
        # Calculate standard deviation
        sigma = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon

        # Generate Gaussian noise
        noise = np.random.normal(0, sigma)

        return value + noise

    @staticmethod
    def noisy_count(
        true_count: int,
        epsilon: float = 1.0
    ) -&gt; int:
        """Return differentially private count."""
        noisy_value = DifferentialPrivacy.add_laplace_noise(
            float(true_count),
            epsilon=epsilon,
            sensitivity=1.0  # Adding/removing one record changes count by 1
        )

        # Round and ensure non-negative
        return max(0, int(round(noisy_value)))

    @staticmethod
    def noisy_average(
        values: List[float],
        epsilon: float = 1.0,
        value_range: tuple = (0, 1)
    ) -&gt; float:
        """Return differentially private average."""
        if not values:
            return 0.0

        # True average
        true_avg = sum(values) / len(values)

        # Sensitivity of average
        min_val, max_val = value_range
        sensitivity = (max_val - min_val) / len(values)

        # Add noise
        noisy_avg = DifferentialPrivacy.add_laplace_noise(
            true_avg,
            epsilon=epsilon,
            sensitivity=sensitivity
        )

        # Clamp to valid range
        return max(min_val, min(max_val, noisy_avg))

# Example usage
# # True count: 1000 users
# private_count = DifferentialPrivacy.noisy_count(1000, epsilon=1.0)
# # Returns approximately 1000 ± noise
#
# # True average: 0.85
# task_success_rates = [0.9, 0.8, 0.85, 0.9]
# private_avg = DifferentialPrivacy.noisy_average(
#     task_success_rates,
#     epsilon=1.0,
#     value_range=(0, 1)
# )
</code></pre>
<h3 id="k-anonymity"><a class="header" href="#k-anonymity">K-Anonymity</a></h3>
<p>Implement k-anonymity for data release:</p>
<pre><code class="language-python">import pandas as pd
from typing import List

class KAnonymity:
    """K-anonymity implementation for data publishing."""

    @staticmethod
    def generalize_value(value: str, level: int) -&gt; str:
        """Generalize a value to reduce granularity."""
        # Example: ZIP code generalization
        if isinstance(value, str) and value.isdigit() and len(value) == 5:
            if level == 1:
                return value[:4] + "*"  # 12345 -&gt; 1234*
            elif level == 2:
                return value[:3] + "**"  # 12345 -&gt; 123**
            elif level &gt;= 3:
                return value[:2] + "***"  # 12345 -&gt; 12***

        # Example: Age generalization
        if isinstance(value, int):
            if level == 1:
                return f"{(value // 10) * 10}-{(value // 10) * 10 + 9}"
            elif level &gt;= 2:
                return f"{(value // 20) * 20}-{(value // 20) * 20 + 19}"

        return value

    @staticmethod
    def achieve_k_anonymity(
        df: pd.DataFrame,
        quasi_identifiers: List[str],
        k: int = 10
    ) -&gt; pd.DataFrame:
        """Generalize data to achieve k-anonymity."""
        df_anonymized = df.copy()

        # Iteratively generalize until k-anonymity achieved
        level = 0
        max_iterations = 10

        while level &lt; max_iterations:
            # Group by quasi-identifiers
            groups = df_anonymized.groupby(quasi_identifiers).size()

            # Check if all groups have at least k members
            if groups.min() &gt;= k:
                break

            # Generalize the quasi-identifier with least generalization
            for qi in quasi_identifiers:
                df_anonymized[qi] = df_anonymized[qi].apply(
                    lambda x: KAnonymity.generalize_value(x, level)
                )

            level += 1

        return df_anonymized

    @staticmethod
    def verify_k_anonymity(
        df: pd.DataFrame,
        quasi_identifiers: List[str],
        k: int
    ) -&gt; bool:
        """Verify that dataset satisfies k-anonymity."""
        groups = df.groupby(quasi_identifiers).size()
        return groups.min() &gt;= k

# Example usage
# data = pd.DataFrame({
#     "name": ["Alice", "Bob", "Charlie", "David"],
#     "zip_code": ["12345", "12346", "12347", "12348"],
#     "age": [25, 28, 30, 32],
#     "diagnosis": ["Flu", "Cold", "Flu", "Cold"]
# })
#
# quasi_identifiers = ["zip_code", "age"]
#
# # Achieve 2-anonymity
# anonymized = KAnonymity.achieve_k_anonymity(data, quasi_identifiers, k=2)
#
# # Verify
# is_anonymous = KAnonymity.verify_k_anonymity(anonymized, quasi_identifiers, k=2)
</code></pre>
<h3 id="l-diversity"><a class="header" href="#l-diversity">L-Diversity</a></h3>
<p>Extend k-anonymity with l-diversity:</p>
<pre><code class="language-python">class LDiversity:
    """L-diversity implementation for protecting sensitive attributes."""

    @staticmethod
    def verify_l_diversity(
        df: pd.DataFrame,
        quasi_identifiers: List[str],
        sensitive_attribute: str,
        l: int
    ) -&gt; bool:
        """Verify that dataset satisfies l-diversity."""
        # Group by quasi-identifiers
        groups = df.groupby(quasi_identifiers)

        for name, group in groups:
            # Count distinct values of sensitive attribute
            distinct_values = group[sensitive_attribute].nunique()

            if distinct_values &lt; l:
                return False

        return True

    @staticmethod
    def achieve_l_diversity(
        df: pd.DataFrame,
        quasi_identifiers: List[str],
        sensitive_attribute: str,
        l: int
    ) -&gt; pd.DataFrame:
        """Suppress or generalize to achieve l-diversity."""
        df_diverse = df.copy()

        # Group by quasi-identifiers
        groups = df_diverse.groupby(quasi_identifiers)

        rows_to_suppress = []

        for name, group in groups:
            # Count distinct sensitive values
            distinct_values = group[sensitive_attribute].nunique()

            if distinct_values &lt; l:
                # Suppress this group (mark for removal)
                rows_to_suppress.extend(group.index.tolist())

        # Remove suppressed rows
        df_diverse = df_diverse.drop(rows_to_suppress)

        return df_diverse

# Example
# # This group has 5 people with zip 123**
# # But only 2 distinct diagnoses (Flu, Cold)
# # Not 3-diverse!
#
# anonymized = LDiversity.achieve_l_diversity(
#     anonymized,
#     quasi_identifiers=["zip_code", "age"],
#     sensitive_attribute="diagnosis",
#     l=3
# )
</code></pre>
<h3 id="privacy-budgets"><a class="header" href="#privacy-budgets">Privacy Budgets</a></h3>
<p>Track privacy budget consumption:</p>
<pre><code class="language-python">class PrivacyBudget:
    """Track and enforce privacy budget limits."""

    def __init__(self, total_epsilon: float = 10.0):
        self.total_epsilon = total_epsilon
        self.consumed_epsilon = 0.0
        self.query_log = []

    def consume(self, epsilon: float, query_desc: str) -&gt; bool:
        """Consume privacy budget for a query."""
        if self.consumed_epsilon + epsilon &gt; self.total_epsilon:
            logger.warning(
                "privacy_budget_exceeded",
                consumed=self.consumed_epsilon,
                requested=epsilon,
                total=self.total_epsilon
            )
            return False

        self.consumed_epsilon += epsilon
        self.query_log.append({
            "timestamp": datetime.utcnow(),
            "epsilon": epsilon,
            "query": query_desc,
            "remaining": self.total_epsilon - self.consumed_epsilon
        })

        logger.info(
            "privacy_budget_consumed",
            epsilon=epsilon,
            consumed=self.consumed_epsilon,
            remaining=self.total_epsilon - self.consumed_epsilon
        )

        return True

    def get_remaining(self) -&gt; float:
        """Get remaining privacy budget."""
        return self.total_epsilon - self.consumed_epsilon

    def reset(self):
        """Reset privacy budget (e.g., for new time period)."""
        self.consumed_epsilon = 0.0
        self.query_log = []

# Example usage
# budget = PrivacyBudget(total_epsilon=10.0)
#
# # Query 1: Count users (epsilon=1.0)
# if budget.consume(1.0, "Count total users"):
#     count = DifferentialPrivacy.noisy_count(true_count, epsilon=1.0)
#
# # Query 2: Average task success (epsilon=0.5)
# if budget.consume(0.5, "Average task success rate"):
#     avg = DifferentialPrivacy.noisy_average(success_rates, epsilon=0.5)
#
# # Check remaining budget
# remaining = budget.get_remaining()  # 8.5
</code></pre>
<hr />
<p>Due to length constraints, I'll continue this document in the next message with the remaining sections:</p>
<ul>
<li>Implementation Integration</li>
<li>Testing and Validation</li>
<li>Operational Procedures</li>
</ul>
<p>This document is at approximately 1,850 lines so far. Would you like me to continue with the remaining sections?</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../security/capability-isolation.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../security/secrets-management.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../security/capability-isolation.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../security/secrets-management.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
